{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "5_3_LOADING_A_TORCHSCRIPT_MODEL_IN_Cpp_jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4EsY39y_bO"
      },
      "source": [
        "「C++でのTorchScriptモデルのロード手法」\n",
        "======================================\n",
        "【原題】LOADING A TORCHSCRIPT MODEL IN C++\n",
        "\n",
        "【原著】記載なし\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/advanced/cpp_export.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID AIトランスフォーメーションセンター　小川 雄太郎\n",
        "\n",
        "【日付】2020年10月27日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "本チュートリアルでは、TorchScriptを利用して、C++環境でモデルを実行可能に変換する手順と、実際にC++で実行する方法について解説します。\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqgDh7boJn0a"
      },
      "source": [
        "PyTorchという名前の通り、PyTorchのメインのインターフェースはPythonです。\n",
        "\n",
        "Pythonは柔軟で手軽に使用しやすいプログラミング言語ですが、Pythonのこれらの特性が好ましくない状況もあります。\n",
        "\n",
        "Pythonの適用が難しい環境の一つがプロダクション、製品です。\n",
        "\n",
        "製品では低レイテンシと厳しいデプロイメント要件が求められます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFze5rEzXF0D"
      },
      "source": [
        "プロダクション、製品の場合にはC++ が選択されるケースが多いです（Java、Rust、Goなどの他の言語と併用する場合も含める）。\r\n",
        "\r\n",
        "本チュートリアルでは、既存の Pythonモデルから、Python環境に依存することなく、C++環境でロードして実行できる、シリアライズされた表現（モデル）へと変換するする手順の概要を説明します。\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tVgdbRdsdO-"
      },
      "source": [
        "Step 1: PyTorch Model を Torch Scriptに変換する\n",
        "=====\n",
        "\n",
        "---\n",
        "PyTorchモデルのPythonからC++への変換は、Torch Scriptを利用することで可能になります。\n",
        "\n",
        "Torch Scriptは、Torch Scriptコンパイラによって解釈、コンパイル、シリアライズ化されたPyTorchモデルの表現手法の一種です。\n",
        "\n",
        "<br>\n",
        "\n",
        " \"eager\" API で書かれた既存の PyTorch モデルで作成している場合は、まずモデルを Torch Script に変換する必要があります。\n",
        "\n",
        "（日本語訳注： \"eager\" APIとは、いわゆる普通のPyTorchの使い方だと思っていください。Define by Runのことです。）\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6UnqYcoX2af"
      },
      "source": [
        "\r\n",
        "一般的なケースでは、後ほど解説するように、この変換はほんの少しの実装で実現できます。\r\n",
        "\r\n",
        "すでに Torch Scriptのモジュールを用意できている場合は、本チュートリアルの次のセクションに進んでください。\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODz4ZM_sM6oL"
      },
      "source": [
        "PyTorchモデルをTorch Scriptに変換するには、2つの方法があります。\n",
        "\n",
        "<br>\n",
        "\n",
        "1つ目はトレース（tracing）と呼ばれる方法です。モデルにサンプル入力を与え、一度推論計算を実施し、その入力から出力までの計算の流れをモデルに記録することで、モデルの構造を把握する仕組みです。\n",
        "\n",
        "この方法は、制御フローの利用（if文、for文など）が限られているモデルに適しています。\n",
        "\n",
        "<br>\n",
        "\n",
        "2つ目の手法は、Torch Script コンパイラがモデルコードを直接解析してコンパイルすることができるように、モデルに明示的なアノテーションを追加する方法、スクリプトです（scripting）。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9A0btzUNwkt"
      },
      "source": [
        "【ポイント】\n",
        "\n",
        "上記の2つ手法についての、正確な説明や内容、使い分けについては、[Torch Script reference](https://pytorch.org/docs/master/jit.html)も参考にしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS6b_9rWObKA"
      },
      "source": [
        "**tracingによるTorch Scriptへの変換**\n",
        "\n",
        "\n",
        "tracingを使ってPyTorchモデルをTorch Scriptに変換するには、モデルのインスタンスと入力データの例を、torch.jit.trace関数に渡します。\n",
        "\n",
        "これにより、モデルの順伝搬の計算の流れをモジュールのフォワードメソッドとして用意した torch.jit.ScriptModule オブジェクトが作成できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHxQKxKCO_ny"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuFDgBNhNwAi"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# An instance of your model.\n",
        "model = torchvision.models.resnet18()\n",
        "\n",
        "# An example input you would normally provide to your model's forward() method.\n",
        "example = torch.rand(1, 3, 224, 224)\n",
        "\n",
        "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
        "traced_script_module = torch.jit.trace(model, example)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUE2kVuEPQDt"
      },
      "source": [
        "tracingで作られたモジュール（ScriptModule）は、通常のPyTorchモジュールと同じように使用できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zzKsfpzMob0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a8e391-31b6-4247-ddad-ef6123f8e8ff"
      },
      "source": [
        "output = traced_script_module(torch.ones(1, 3, 224, 224))\n",
        "output[0, :5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.9378, -0.6521,  0.1187,  0.7416, -0.3259], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLaGUo8Jhrqk"
      },
      "source": [
        "（日本語訳注：英語版チュートリアルページとは結果が異なります。訓練済みモデルがアップデートされたのかもしれません）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdFO5K1NP06c"
      },
      "source": [
        "**scriptingによるTorch Scriptへの変換**\n",
        "\n",
        "モデルの順伝搬が、特定の形式の制御フロー（if文やfor文など）を使用しているなど、特定の状況下の場合には、Torch Scriptで直接モデルを記述します。\n",
        "\n",
        "例えば、以下のような通常のPytorchモデルがあると仮定します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GU8s1rPQcpB"
      },
      "source": [
        "import torch\n",
        "\n",
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self, N, M):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.sum() > 0:\n",
        "          output = self.weight.mv(input)\n",
        "        else:\n",
        "          output = self.weight + input\n",
        "        return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtB5jEtiRFEp"
      },
      "source": [
        "このモジュールの順伝搬（フォワードメソッド）は入力に依存した制御フロー（if文）を使用しているため、tracingでの変換には適していません。\n",
        "\n",
        "ですが、scrptingで、ScriptModuleに変換することができます。\n",
        "\n",
        "ScriptModuleに変換するには、以下のようにtorch.jit.scriptでコンパイルする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPe9PHZ_QtQS"
      },
      "source": [
        "class MyModule(torch.nn.Module):\n",
        "    def __init__(self, N, M):\n",
        "        super(MyModule, self).__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.sum() > 0:\n",
        "          output = self.weight.mv(input)\n",
        "        else:\n",
        "          output = self.weight + input\n",
        "        return output\n",
        "\n",
        "my_module = MyModule(10,20)\n",
        "sm = torch.jit.script(my_module)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTOdkBHuRW4I"
      },
      "source": [
        "nn.Moduleの中で、TorchScriptがまだサポートしていないPythonの機能を使っているメソッドを除外する必要がある場合は、``@torch.jit.ignore``のアノテーションを付けておきます。\n",
        "\n",
        "変数``my_module`` は、シリアライズ化されたScriptModule のインスタンスです。\n",
        "\n",
        "（日本語訳注：英語版では、変数``my_module``と記載されているのですが、正しくは、変数``sm``がScriptModuleのインスタンスです。）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEOQwQ0IVXA8"
      },
      "source": [
        "Step 2:シリアライズ化されたScriptモジュールをファイルに保存する\n",
        "=====\n",
        "\n",
        "---\n",
        "tracingや、PyTorchモデルのscriptingでScriptModuleを作成できたら、ファイルへと変換する準備は完了です。\n",
        "\n",
        "今後はC++でこのファイルからモジュールをロードすれば、Pythonに依存せずにモデルを実行できるようになります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66QVi2-TZs45"
      },
      "source": [
        "先ほどのtracingの例で示した ResNet18 モデルを保存するとしましょう。\r\n",
        "\r\n",
        "このファイルへのシリアライズ（ファイル保存）を実行するには、モジュールの [save](https://pytorch.org/docs/master/jit.html#torch.jit.ScriptModule.save) を呼び出してファイル名を渡すだけです。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ4StrkLQgYD"
      },
      "source": [
        "traced_script_module.save(\"traced_resnet_model.pt\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__h7QW5PWPo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "991e4737-6796-4cb3-a247-a3f70cbe0ea2"
      },
      "source": [
        "# 日本語訳注：実際に保存されたファイル「traced_resnet_model.pt」があるか確かめてみましょう\n",
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  traced_resnet_model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyQhQ_ykWecT"
      },
      "source": [
        "上記のコードにより、作業ディレクトリにtraced_resnet_model.ptファイルが生成されました。\n",
        "\n",
        "scrptingで作成した``my_module`` をシリアライズしたい場合は、 ``my_module.save(\"my_module_model.pt\")`` と実装してください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8AeRL7RW3Uj"
      },
      "source": [
        "Step 3: C++でScriptモジュールのファイルをロードする\n",
        "=====\n",
        "\n",
        "---\n",
        "シリアライズされたPyTorchモデルをC++でロードするには、アプリケーションはPyTorch C++ API（LibTorchと呼ばれます）をincludeする必要があります。\n",
        "\n",
        "LibTorch ディストリビューションには、共有ライブラリ、ヘッダファイル、CMakeビルド設定ファイルの一式が含まれています。\n",
        "\n",
        "<br>\n",
        "\n",
        "CMake は LibTorch をincludeするための必須条件ではありませんが、推奨されるアプローチであり、将来的には十分にサポートされるでしょう。\n",
        "\n",
        "本チュートリアルでは、CMakeとLibTorchを使って、シリアル化されたPyTorchモデルをロードして実行するだけの最小限のC++アプリケーションを構築します。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMo2IMthYS6g"
      },
      "source": [
        "**最小限のC++アプリケーション**\n",
        "\n",
        "まず、モジュールをロードするコードについて説明します。\n",
        "\n",
        "以下のように実装します。\n",
        "\n",
        "（日本語訳注：以下、C++のプログラムになるので、実行はできません。C++環境でお試しください）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5DZ08_HXnwT"
      },
      "source": [
        "%%writefile example-app.cpp\n",
        "\n",
        "#include <torch/script.h> // One-stop header.\n",
        "\n",
        "#include <iostream>\n",
        "#include <memory>\n",
        "\n",
        "int main(int argc, const char* argv[]) {\n",
        "  if (argc != 2) {\n",
        "    std::cerr << \"usage: example-app <path-to-exported-script-module>\\n\";\n",
        "    return -1;\n",
        "  }\n",
        "\n",
        "\n",
        "  torch::jit::script::Module module;\n",
        "  try {\n",
        "    // Deserialize the ScriptModule from a file using torch::jit::load().\n",
        "    module = torch::jit::load(argv[1]);\n",
        "  }\n",
        "  catch (const c10::Error& e) {\n",
        "    std::cerr << \"error loading the model\\n\";\n",
        "    return -1;\n",
        "  }\n",
        "\n",
        "  std::cout << \"ok\\n\";\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nuMKK-VYv6z"
      },
      "source": [
        "<torch/script.h> ヘッダーで、サンプルの実行に必要な内容が、LibTorch ライブラリからすべてincludeされます。\n",
        "\n",
        "このアプリケーションは、ファイルに変換されたPyTorch ScriptModuleのファイルパスをコマンドライン引数として受け取り、このファイルパスを入力として受け取るtorch::jit::load()関数を使用して、モジュールをデシリアライズします（戻す変換）。\n",
        "\n",
        "次に、torch::jit::script::Module オブジェクトをインスタンス化しています。\n",
        "\n",
        "モデルの実行方法については、次に解説します。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHxCdxCsZk1X"
      },
      "source": [
        "**LibTorchの導入とアプリケーションの構築**\n",
        "\n",
        "\n",
        "上記のコードを example-app.cpp というファイルとして、保存したとします。\n",
        "\n",
        "これをビルドするための最小限の CMakeLists.txt は、次のようなシンプルな内容になります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2W3Zw0GaBaW"
      },
      "source": [
        "```\n",
        "cmake_minimum_required(VERSION 3.0 FATAL_ERROR)\n",
        "project(custom_ops)\n",
        "\n",
        "find_package(Torch REQUIRED)\n",
        "\n",
        "add_executable(example-app example-app.cpp)\n",
        "target_link_libraries(example-app \"${TORCH_LIBRARIES}\")\n",
        "set_property(TARGET example-app PROPERTY CXX_STANDARD 14)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWrLchCWaQOz"
      },
      "source": [
        "サンプルアプリケーションをビルドするために、あと必要となるものが、 LibTorch ディストリビューションです。\n",
        "\n",
        "PyTorch のウェブサイトの[ダウンロードページ](https://pytorch.org/)から、最新の安定版を入手することができます。\n",
        "\n",
        "最新のアーカイブをダウンロードして解凍すると、以下のようなディレクトリ構造のフォルダが生成されます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xHLAbJ-ah_S"
      },
      "source": [
        "```\n",
        "libtorch/\n",
        "  bin/\n",
        "  include/\n",
        "  lib/\n",
        "  share/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b7wx7f3ct8y"
      },
      "source": [
        "- lib/ フォルダには、リンクする必要がある共有ライブラリが含まれています。\n",
        "\n",
        "- include/フォルダには、プログラムがインクルードする必要があるヘッダファイルが含まれています。\n",
        "\n",
        "- share/フォルダには、上記のシンプルなfind_package(Torch)コマンド（上記で記述したCMakeLists.txt で利用するコマンドです）を有効にするために必要なCMakeの設定が含まれています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96T-mnBPdVzA"
      },
      "source": [
        "【ヒント】\n",
        "\n",
        "Windowsでは、デバッグビルドとリリースビルドはABI互換性がありません（＝Application Binary Interfaceではない）。\n",
        "\n",
        " デバッグモードでプロジェクトをビルドする場合は、LibTorchのデバッグバージョンを試してみてください。\n",
        "\n",
        "また、以下の cmake --build .　の行で正しい設定を指定してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTs5Evy6d10M"
      },
      "source": [
        "最後のステップはアプリケーションの構築です。\n",
        "\n",
        "ここでは、ディレクトリが以下のようにレイアウトされていると仮定します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaeGTsmkd-5R"
      },
      "source": [
        "```\n",
        "example-app/\n",
        "  CMakeLists.txt\n",
        "  example-app.cpp\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrld_j4TeIRx"
      },
      "source": [
        "example-app/フォルダ内で、次のコマンドを実行してアプリケーションをビルドすることができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmngMZ0rePIQ"
      },
      "source": [
        "```\n",
        "mkdir build\n",
        "cd build\n",
        "cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch ..\n",
        "cmake --build . --config Release\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbAMhx8JeWM_"
      },
      "source": [
        "ここで、/path/to/libtorch は、解凍した LibTorch ディストリビューションへのフルパスを示します（各ユーザーの環境、LitTorchが導入されたパスに合わせてください）。\n",
        "\n",
        "すべてがうまくいくと、以下のように表示されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS8yc_oBeh2Z"
      },
      "source": [
        "```\n",
        "root@4b5a67132e81:/example-app# mkdir build\n",
        "root@4b5a67132e81:/example-app# cd build\n",
        "root@4b5a67132e81:/example-app/build# cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch ..\n",
        "-- The C compiler identification is GNU 5.4.0\n",
        "-- The CXX compiler identification is GNU 5.4.0\n",
        "-- Check for working C compiler: /usr/bin/cc\n",
        "-- Check for working C compiler: /usr/bin/cc -- works\n",
        "-- Detecting C compiler ABI info\n",
        "-- Detecting C compiler ABI info - done\n",
        "-- Detecting C compile features\n",
        "-- Detecting C compile features - done\n",
        "-- Check for working CXX compiler: /usr/bin/c++\n",
        "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
        "-- Detecting CXX compiler ABI info\n",
        "-- Detecting CXX compiler ABI info - done\n",
        "-- Detecting CXX compile features\n",
        "-- Detecting CXX compile features - done\n",
        "-- Looking for pthread.h\n",
        "-- Looking for pthread.h - found\n",
        "-- Looking for pthread_create\n",
        "-- Looking for pthread_create - not found\n",
        "-- Looking for pthread_create in pthreads\n",
        "-- Looking for pthread_create in pthreads - not found\n",
        "-- Looking for pthread_create in pthread\n",
        "-- Looking for pthread_create in pthread - found\n",
        "-- Found Threads: TRUE\n",
        "-- Configuring done\n",
        "-- Generating done\n",
        "-- Build files have been written to: /example-app/build\n",
        "root@4b5a67132e81:/example-app/build# make\n",
        "Scanning dependencies of target example-app\n",
        "[ 50%] Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o\n",
        "[100%] Linking CXX executable example-app\n",
        "[100%] Built target example-app\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vxFdvgPesbe"
      },
      "source": [
        "先ほどtracingで作成したResNet18モデルのファイル、traced_resnet_model.ptへのパスを、生成されたexample-appバイナリに与えると、「ok」と返ってくるはずです。\n",
        "\n",
        "<br>\n",
        "\n",
        "なお、以下の例を my_module_model.pt と一緒に実行しようとすると、「入力の形状が不適合です」というエラーが出る点に注意してください。\n",
        "\n",
        "なぜなら、my_module_model.pt は 入力が4 次元ではなく 1 次元を想定しているからです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRoI3m1WfHGB"
      },
      "source": [
        "```\n",
        "root@4b5a67132e81:/example-app/build# ./example-app\n",
        "<path_to_model>/traced_resnet_model.pt\n",
        "ok\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa8-e7zIfklj"
      },
      "source": [
        "Step 4: C++でScriptモジュールを実行する\n",
        "=====\n",
        "\n",
        "---\n",
        "C++ でシリアル化された ResNet18 のロードに成功したので、あと数行で、モデルが実行できる段階まで到達しました。\n",
        "\n",
        "以下の内容を、C++ アプリケーションの main() 関数に追加してみましょう。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8_2reKjf5O8"
      },
      "source": [
        "```\n",
        "// Create a vector of inputs.\n",
        "std::vector<torch::jit::IValue> inputs;\n",
        "inputs.push_back(torch::ones({1, 3, 224, 224}));\n",
        "\n",
        "// Execute the model and turn its output into a tensor.\n",
        "at::Tensor output = module.forward(inputs).toTensor();\n",
        "std::cout << output.slice(/*dim=*/1, /*start=*/0, /*end=*/5) << '\\n';\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1H_e0gxgELB"
      },
      "source": [
        "最初の2行は、モデルへの入力を設定しています\n",
        "\n",
        "torch::jit::IValue (script::Module メソッドが受け付けて返す、型が消された値です)、 のベクトル変数を作成し、入力として追加します。\n",
        "\n",
        "<br>\n",
        "\n",
        "次に script::Module の forwardメソッドに作成した入力ベクトルを渡して実行します。\n",
        "\n",
        "戻り値として新たなIValueを取得し、これを toTensor()メソッドを呼び出して、テンソルの形に変換します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfKMNMRWgmBQ"
      },
      "source": [
        "【ヒント】\n",
        "\n",
        "torch::ones のような関数や PyTorch C++ API の一般的な使い方については、https://pytorch.org/cppdocs のドキュメントを参照してください。\n",
        "\n",
        " PyTorch C++ API は Python API とほぼ同等の機能を提供しており、Python と同様にテンソルを操作したり処理したりすることができます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji4drwJfg5lo"
      },
      "source": [
        "最後の行では、出力の最初の5つの要素を表示します。\n",
        "\n",
        "このチュートリアルの冒頭部分でPythonでモデルに同じ入力を与えたので、理想的には同じ出力が表示されるはずです。\n",
        "\n",
        "アプリケーションを再コンパイルして、同じシリアル化されたモデルで実行してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnZB3RpuhHu7"
      },
      "source": [
        "```\n",
        "root@4b5a67132e81:/example-app/build# make\n",
        "Scanning dependencies of target example-app\n",
        "[ 50%] Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o\n",
        "[100%] Linking CXX executable example-app\n",
        "[100%] Built target example-app\n",
        "root@4b5a67132e81:/example-app/build# ./example-app traced_resnet_model.pt\n",
        "-0.2698 -0.0381  0.4023 -0.3010 -0.0448\n",
        "[ Variable[CPUFloatType]{1,5} ]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMxUAF6_hd30"
      },
      "source": [
        "参考までに、以前はPythonでの出力次の通りでした。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4B_vKU0h_Jy"
      },
      "source": [
        "```python\n",
        "tensor([-0.2698, -0.0381,  0.4023, -0.3010, -0.0448], grad_fn=<SliceBackward>)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-o97JriEBx"
      },
      "source": [
        "うまく、一致しています！\n",
        "\n",
        "（日本語訳注：英語のチュートリアルページとは結果が異なります。訓練済みモデルがアップデートされた影響と思われます。。）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIembvbziK5K"
      },
      "source": [
        "【ヒント】\n",
        "\n",
        "モデルをGPUメモリに移動し、GPU上で実行するには、model.to(at::kCUDA);と実装します。\n",
        "\n",
        "tensor.to(at::kCUDA)を呼び出すことで、モデルへの入力データもCUDAメモリ内に新たに作られます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLk1K5eAi1l-"
      },
      "source": [
        "Step 5: ヘルプページとAPIの解説\n",
        "=====\n",
        "\n",
        "---\n",
        "本チュートリアルを通して、Python から C++環境へ PyTorchモデルを変換する手順を、概念的に理解していただけたかと思います。\n",
        "\n",
        "本チュートリアルで説明した内容を使えば、素の“eager”モードのPyTorchモデルから、\n",
        "\n",
        "- コンパイルされたScriptModule（Python環境で動作）\n",
        "- ディスク上に保存されたファイル\n",
        "- C++で実行可能なscript::Module\n",
        "\n",
        "へと、変換することができます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgcKGMflkD8Q"
      },
      "source": [
        "もちろん、本チュートリアルでは説明しきれなかった概念もたくさんあります。\n",
        "\n",
        "<br>\n",
        "\n",
        "たとえば、C++ や CUDA で実装されたカスタム演算子で ScriptModuleを拡張し、そのカスタム演算子を、純粋なC++の本番環境で読み込んで、ScriptModule内で実行したいと思うかもしれません。\n",
        "\n",
        "このようなことは可能であり、実際にサポートされているという朗報があります。\n",
        "\n",
        "今のところは、[このフォルダ](https://github.com/pytorch/pytorch/tree/master/test/custom_operator)からサンプルを探してみてください。\n",
        "\n",
        "その他、以下のリンク先の情報が役立つでしょう。\n",
        "\n",
        "- The Torch Script のリファレンス: https://pytorch.org/docs/master/jit.html\n",
        "- The PyTorch C++ APIのドキュメント: https://pytorch.org/cppdocs/\n",
        "- The PyTorch Python APIのドキュメント: https://pytorch.org/docs/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhSdVzKikxJJ"
      },
      "source": [
        "何か問題が発生したり質問がある場合は、[フォーラム](https://discuss.pytorch.org/)や [GitHubのIssue](https://github.com/pytorch/pytorch/issues)を活用することもできます。"
      ]
    }
  ]
}