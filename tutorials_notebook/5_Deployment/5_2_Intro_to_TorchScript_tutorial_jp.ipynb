{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Intro_to_TorchScript_tutorial_jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyVJahOH5_dt"
      },
      "source": [
        "\n",
        "「TorchScript入門」\n",
        "===============================================================\n",
        "【原題】INTRODUCTION TO TORCHSCRIPT\n",
        "\n",
        "【原著者】James Reed (jamesreed@fb.com), Michael Suo (suo@fb.com)\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID AIトランスフォーメーションセンター　小川 雄太郎\n",
        "\n",
        "【日付】2020年10月24日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "本チュートリアルでは、PyTorchモデルのモデル構造について簡単に説明したあと、TorchScriptと呼ばれる手法について、概要と使用方法を解説します。\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b8gu6a25ijb"
      },
      "source": [
        "本チュートリアルでは、TorchScriptについて紹介します。\n",
        "\n",
        "TorchScriptは``nn.Module``から構成されたPyTochモデルの中間表現であり、C++のような高速な実行環境でモデルを実行することができます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWyvs6P3G61A"
      },
      "source": [
        "本チュートリアルでは、以下の内容を解説します。\r\n",
        "\r\n",
        "1. PyTorchで作られモデルの基礎的内容、とくに\r\n",
        "- Module（モジュール）\r\n",
        "-  ``forward`` 関数\r\n",
        "- モジュールを階層的に変換する方法\r\n",
        "\r\n",
        "<br>\r\n",
        "\r\n",
        "2. 特定の手法でPyTorchのモジュールを、高性能なデプロイ環境で実行可能なTorchScripに変換する方法、とくに\r\n",
        "\r\n",
        "- モジュールをトレースする方法（Tracing)\r\n",
        "- コードを直接モジュールにするスクリプトの方法（scripting）\r\n",
        "- 上記2つの方法の相互利用と同時利用の方法\r\n",
        "- TorchScriptモジュールの保存とロード方法\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VwGv2zfHFR8"
      },
      "source": [
        "本チュートリアルが終了した際には、ぜひこの次のチュートリアルである、「C++でのTorchScriptモデルのロード手法」（LOADING A TORCHSCRIPT MODEL IN C++）にも挑戦してみてください。\r\n",
        "\r\n",
        "次のチュートリアルでは、C++からTorchScriptを実行する方法について解説しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGNFEMvE87jP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1ebfed-42c0-4350-ac91-d9de2663b6cc"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch  # This is all you need to use both PyTorch and TorchScript!\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0UHtJn-5ije"
      },
      "source": [
        "PyTochモデルの基本構成\n",
        "---------------------------------\n",
        "\n",
        "簡単なモジュールを定義してみましょう。\n",
        "\n",
        "``Module``はPyTorchを構成する基本ユニットです。\n",
        "\n",
        "``Module``には以下の内容が含まれています。\n",
        "\n",
        "1. モジュールを呼び出すための準備となるコンストラクタ\n",
        "2. 一連の``Parameters`'と、サブ``Modules``。なおこれらのパラメータとサブモジュールは、モジュールが呼び出されてコンストラクタで初期化された後に、使用できるようになります。\n",
        "3. 順伝搬である``forward``関数。モジュールそのものが呼び出されたときに実行される関数です。\n",
        "\n",
        "まずは簡単な例を確認してみましょう。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2ue1Jvu5ije",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ac58b6-1df0-4668-a076-675115f82372"
      },
      "source": [
        "class MyCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCell, self).__init__()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        new_h = torch.tanh(x + h)\n",
        "        return new_h, new_h\n",
        "\n",
        "my_cell = MyCell()\n",
        "x = torch.rand(3, 4)\n",
        "h = torch.rand(3, 4)\n",
        "print(my_cell(x, h))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[0.4920, 0.8299, 0.5254, 0.8509],\n",
            "        [0.8504, 0.8406, 0.9022, 0.6847],\n",
            "        [0.6422, 0.8253, 0.7027, 0.5935]]), tensor([[0.4920, 0.8299, 0.5254, 0.8509],\n",
            "        [0.8504, 0.8406, 0.9022, 0.6847],\n",
            "        [0.6422, 0.8253, 0.7027, 0.5935]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rXYH7Uj5ijh"
      },
      "source": [
        "上記では\n",
        "\n",
        "1. ``torch.nn.Module``のサブクラスを作成しました。\n",
        "2. コンストラクタを定義しました。\n",
        "コンストラクタは特に多くの処理をしているわけではなく、``super``で親クラスのコンストラクタを実行しているだけです。\n",
        "3. 順伝搬関数``forward``を定義しました。これは2つのパラメータを入力として受け取り、2つの変数を出力します。本チュートリアルでは順伝搬関数の中身は重要ではありませんが、一種の[RNN](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)的な動作を想定し、RNNの一部を実装しました。\n",
        "\n",
        "そして、このモジュールをインスタンス化し、3x4の乱数行列である変数``x``と``y``を用意しました。\n",
        "\n",
        "そして、モジュールを``my_cell(x, h)``で呼び出して実行しています。このモジュールを呼び出して実行すると、関数``forward``が呼び出されて実行されることになります。\n",
        "\n",
        "続いて、さらに面白いことに挑戦してみましょう。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqVZ_NGZ5ijh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6de900b-72fe-447b-b4a2-8499aa386b80"
      },
      "source": [
        "class MyCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCell, self).__init__()\n",
        "        self.linear = torch.nn.Linear(4, 4)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        new_h = torch.tanh(self.linear(x) + h)\n",
        "        return new_h, new_h\n",
        "\n",
        "my_cell = MyCell()\n",
        "print(my_cell)\n",
        "print(my_cell(x, h))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyCell(\n",
            "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
            ")\n",
            "(tensor([[ 0.7103,  0.1837,  0.2306,  0.5142],\n",
            "        [ 0.8638,  0.4461,  0.6245,  0.6464],\n",
            "        [ 0.6585, -0.0320,  0.7657,  0.0201]], grad_fn=<TanhBackward>), tensor([[ 0.7103,  0.1837,  0.2306,  0.5142],\n",
            "        [ 0.8638,  0.4461,  0.6245,  0.6464],\n",
            "        [ 0.6585, -0.0320,  0.7657,  0.0201]], grad_fn=<TanhBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cmCWJ2O5ijk"
      },
      "source": [
        "再度、モジュール``MyCell``を定義しなおしました。\n",
        "\n",
        "今度は、``self.linear``のメンバ変数を追加し、``forward``関数内でこの``self.linear``を呼び出しています。\n",
        "\n",
        "このとき、実際には何が起こっているのでしょうか？\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5jYJt_2H8Bo"
      },
      "source": [
        "``torch.nn.Linear``はPytorchの標準ライブラリで用意されている``Module``です、この ``MyCell``と同じようなものになります。\r\n",
        "\r\n",
        "この``torch.nn.Linear``はモジュール内の関数で、forwardなどをそのまま呼び出すことができます。\r\n",
        "\r\n",
        "結果、モジュールの階層的な構造を構成することができました。\r\n",
        "\r\n",
        "print文でモジュールを出力すると、このモジュールのサブクラスの仮想的表現を確認することができます。\r\n",
        "\r\n",
        "（print(my_cell)の部分）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VqtvWt1IEsa"
      },
      "source": [
        "この例では、サブクラス``Linear``とそのパラメータを確認できています。\r\n",
        "\r\n",
        "このように``Module``を複数使用して構成することで、再利用可能なコンポーネントをから成るモデルを簡潔かつ読みやすく実装することができます。\r\n",
        "\r\n",
        "ここで上記セルの、出力結果にある``grad_fn``の記載が気になるかと思います。\r\n",
        "\r\n",
        "``grad_fn``はPyTorchの自動微分、[`autograd<>`](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)、から詳細をご覧ください。\r\n",
        "\r\n",
        "簡単にはこの自動微分により、複雑なプログラムの偏微分を計算することができます。\r\n",
        "\r\n",
        "PyTorchではこの自動微分がうまく設計され、組み込まれているために、モデル実装の柔軟性が大幅に向上しています。\r\n",
        "\r\n",
        "続ていて、その柔軟性を確かめてみましょう。\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0MktQ2w5ijl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f34346-fb2c-4d9e-8c13-df2a0fb23110"
      },
      "source": [
        "class MyDecisionGate(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        if x.sum() > 0:\n",
        "            return x\n",
        "        else:\n",
        "            return -x\n",
        "\n",
        "class MyCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCell, self).__init__()\n",
        "        self.dg = MyDecisionGate()\n",
        "        self.linear = torch.nn.Linear(4, 4)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
        "        return new_h, new_h\n",
        "\n",
        "my_cell = MyCell()\n",
        "print(my_cell)\n",
        "print(my_cell(x, h))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyCell(\n",
            "  (dg): MyDecisionGate()\n",
            "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
            ")\n",
            "(tensor([[ 0.2030,  0.1072, -0.0427,  0.7238],\n",
            "        [ 0.2365,  0.5272,  0.3636,  0.8485],\n",
            "        [-0.0170,  0.3070,  0.7457,  0.4996]], grad_fn=<TanhBackward>), tensor([[ 0.2030,  0.1072, -0.0427,  0.7238],\n",
            "        [ 0.2365,  0.5272,  0.3636,  0.8485],\n",
            "        [-0.0170,  0.3070,  0.7457,  0.4996]], grad_fn=<TanhBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "styJgKOm5ijq"
      },
      "source": [
        "再度、``MyCell``クラスを定義しなおしました。\n",
        "\n",
        "今回は、一緒に``MyDecisionGate``クラスも定義しています。このモジュールは順伝搬時の流れを制御するために使用します（**control flow**）。\n",
        "\n",
        "多くの場合、順伝搬を制御するために、ループ構文やif文を含んでいます。\n",
        "\n",
        "多くのディープラーニング・フレームワークは完全なモデル表現を必要とします（日本語訳注：そのため**control flow**が使えません）。\n",
        "\n",
        "<br>\n",
        "\n",
        "ですが、PyTorchの場合、勾配計算を連続した記録として扱えます。\n",
        "\n",
        "PyTorchでは実際に計算時に何が行われたのかを記録し、出力の偏微分を求める際にはその記録を逆戻しして計算します。\n",
        "\n",
        "そのためPyTorchでは、事前に完全にモデルの逆伝搬を定義しておく必要がありません。\n",
        "\n",
        "<br>\n",
        "\n",
        "（日本語訳注：このようなPyTorchの特徴はDefine by Runと呼ばれます。一方で先に計算のフローを固定していまう手法は、Define and Runと呼ばれます）\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "自動微分の働きについては以下のアニメーション図も参考にしてみてください。\n",
        "\n",
        "図. [自動微分の動作の様子](https://github.com/pytorch/pytorch/raw/master/docs/source/_static/img/dynamic_graph.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U8cX3j_5ijq"
      },
      "source": [
        "TorchScriptの基本\n",
        "---------------------\n",
        "\n",
        "それでは、サンプルの実行方法と、TorchScriptの使用方法を学んでいきましょう。\n",
        "\n",
        "一言で表すと、TorchScriptはPyTorchの柔軟で動的な性質を考慮しながら、モデルをキャプチャするツールです。\n",
        "\n",
        "まずは、トレース（tracing）による、モジュールのキャプチャを試しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLKmTA1i5ijr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf42ca65-1e03-452f-96e7-ce0811440c46"
      },
      "source": [
        "class MyCell(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCell, self).__init__()\n",
        "        self.linear = torch.nn.Linear(4, 4)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        new_h = torch.tanh(self.linear(x) + h)\n",
        "        return new_h, new_h\n",
        "\n",
        "my_cell = MyCell()\n",
        "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
        "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
        "print(traced_cell)\n",
        "traced_cell(x, h)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyCell(\n",
            "  original_name=MyCell\n",
            "  (linear): Linear(original_name=Linear)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.2750,  0.6314,  0.5681,  0.6225],\n",
              "         [ 0.0644, -0.1122,  0.5933,  0.3037],\n",
              "         [-0.2965,  0.5491,  0.1874,  0.2215]], grad_fn=<TanhBackward>),\n",
              " tensor([[-0.2750,  0.6314,  0.5681,  0.6225],\n",
              "         [ 0.0644, -0.1122,  0.5933,  0.3037],\n",
              "         [-0.2965,  0.5491,  0.1874,  0.2215]], grad_fn=<TanhBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrHfmO6l5ijt"
      },
      "source": [
        "本チュートリアルの2番目に作成した``MyCell``クラスを再定義しています。\n",
        "\n",
        "このクラスの順伝搬を実行する前に、``torch.jit.trace``を使用し、モジュールへの入力の例を渡しています。\n",
        "\n",
        "<br>\n",
        "\n",
        "（日本語訳注：分かりづらいのですが、\n",
        "\n",
        "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
        "\n",
        "の部分です。my_cellで順伝搬させず、入力のサンプルとしてx,hと、そしてモデルmy_cellをtorch.jit.traceに渡して、出力traced_cellを得ています。）\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6ji14FLJMzN"
      },
      "source": [
        "\r\n",
        "ここで実際には何が行われたのでしょうか。\r\n",
        "\r\n",
        "``torch.jit.trace``は``Module``クラスを引数に持っており、このモジュールの順伝搬を実行し、``TracedModule``のインスタンスである``torch.jit.ScriptModule``であるtraced_cellを作成しました。\r\n",
        "\r\n",
        "TorchScriptは中間表現（IR：Intermediate Representation）を記録します。\r\n",
        "\r\n",
        "この中間表現はディープラーニングの界隈ではよく、グラフ（graph）とも呼ばれます。\r\n",
        "\r\n",
        "このグラフは、 ``.graph``プロパティを呼び出すことで確認することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4wXRjvI5iju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882e3eb1-a3fc-4d02-bfee-f969779a3034"
      },
      "source": [
        "print(traced_cell.graph)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "graph(%self.1 : __torch__.MyCell,\n",
            "      %input : Float(3:4, 4:1, requires_grad=0, device=cpu),\n",
            "      %h : Float(3:4, 4:1, requires_grad=0, device=cpu)):\n",
            "  %19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
            "  %21 : Tensor = prim::CallMethod[name=\"forward\"](%19, %input)\n",
            "  %12 : int = prim::Constant[value=1]() # <ipython-input-5-1f6e08af67d0>:7:0\n",
            "  %13 : Float(3:4, 4:1, requires_grad=1, device=cpu) = aten::add(%21, %h, %12) # <ipython-input-5-1f6e08af67d0>:7:0\n",
            "  %14 : Float(3:4, 4:1, requires_grad=1, device=cpu) = aten::tanh(%13) # <ipython-input-5-1f6e08af67d0>:7:0\n",
            "  %15 : (Float(3:4, 4:1, requires_grad=1, device=cpu), Float(3:4, 4:1, requires_grad=1, device=cpu)) = prim::TupleConstruct(%14, %14)\n",
            "  return (%15)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjpyGYY_5ijw"
      },
      "source": [
        "しかしながら、中間表現は非常に低レベルな表現手法（人間には分かりづらく、計算器に扱いやすいレベルの表現手法）です。\n",
        "\n",
        "そのため、グラフ情報の大半はユーザーにとって有用なものではありません。\n",
        "\n",
        "その代わり、``.code``プロパティを使用することで、TorchScriptのコード（グラフ）を解釈しやすいように出力することが可能です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi-SMn0H5ijx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9817a502-0c99-452e-c774-b822dfc39003"
      },
      "source": [
        "print(traced_cell.code)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def forward(self,\n",
            "    input: Tensor,\n",
            "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
            "  _0 = torch.add((self.linear).forward(input, ), h, alpha=1)\n",
            "  _1 = torch.tanh(_0)\n",
            "  return (_1, _1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuglPVR-5ijz"
      },
      "source": [
        "ここまでサンプルを実行しましたが、なんの目的があって、このような操作を行っているのでしょうか？\n",
        "\n",
        "それにはいくつかの理由（利点）はいくつか存在します。\n",
        "\n",
        "1. TorchScriptのコードはPythonのインタプリタではない、独自のインタプリタで呼び出されます。この独自のインタプリタは、Pythonインタプリタとは異なり、Global Interpreter Lockにひっかからないので、同じインスタンスを、同時に複数のリクエストで処理することができます。\n",
        "\n",
        "2. TorchScriptのフォーマットはモデルの全情報を保存し、異なる環境、例えばPython以外の言語で書かれたサーバーでもロードが可能です。\n",
        "\n",
        "3. TorchScriptはコンパイラに最適化されており、実行が、より効率的になります。\n",
        "\n",
        "4. TorchScriptは様々なバックエンドやデバイス環境で実行可能であり、個別の実行演算を持つ各種プログラムにモデルを変換するよりも適用範囲が広いです。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB2TCAbwJ2xT"
      },
      "source": [
        "``traced_cell``を呼び出すことでも、元のモジュールのPythonインスタンス``my_cell``を呼び出した結果と同じ内容を得ることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_aDpSe5ijz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "a245f2f0-8606-40be-e196-4a2343186bad"
      },
      "source": [
        "print(my_cell(x, h))\n",
        "print(traced_cell(x, h))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 0.6958,  0.1292,  0.0430,  0.1840],\n",
            "        [ 0.7851,  0.2323, -0.2598,  0.2947],\n",
            "        [ 0.5422, -0.1874, -0.4077, -0.0105]], grad_fn=<TanhBackward>), tensor([[ 0.6958,  0.1292,  0.0430,  0.1840],\n",
            "        [ 0.7851,  0.2323, -0.2598,  0.2947],\n",
            "        [ 0.5422, -0.1874, -0.4077, -0.0105]], grad_fn=<TanhBackward>))\n",
            "(tensor([[ 0.6958,  0.1292,  0.0430,  0.1840],\n",
            "        [ 0.7851,  0.2323, -0.2598,  0.2947],\n",
            "        [ 0.5422, -0.1874, -0.4077, -0.0105]],\n",
            "       grad_fn=<DifferentiableGraphBackward>), tensor([[ 0.6958,  0.1292,  0.0430,  0.1840],\n",
            "        [ 0.7851,  0.2323, -0.2598,  0.2947],\n",
            "        [ 0.5422, -0.1874, -0.4077, -0.0105]],\n",
            "       grad_fn=<DifferentiableGraphBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9H4yMkG5ij1"
      },
      "source": [
        "TorchScriptを利用したモジュールの変換\n",
        "----------------------------------\n",
        "\n",
        "先ほどの実装コードで、の2番目の実装例`MyCell`を使用し、3番目の\n",
        "control-flow-ladenサブモジュール（control flowモジュールを含むもの）を使わなかったのには理由があります。\n",
        "\n",
        "その理由を確認してみましょう。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtWk7fc25ij2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1685223c-d0ce-491d-981f-fb9cf9d6b40e"
      },
      "source": [
        "class MyDecisionGate(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        if x.sum() > 0:\n",
        "            return x\n",
        "        else:\n",
        "            return -x\n",
        "\n",
        "class MyCell(torch.nn.Module):\n",
        "    def __init__(self, dg):\n",
        "        super(MyCell, self).__init__()\n",
        "        self.dg = dg\n",
        "        self.linear = torch.nn.Linear(4, 4)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
        "        return new_h, new_h\n",
        "\n",
        "my_cell = MyCell(MyDecisionGate())\n",
        "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
        "print(traced_cell.code)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def forward(self,\n",
            "    input: Tensor,\n",
            "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
            "  _0 = self.dg\n",
            "  _1 = (self.linear).forward(input, )\n",
            "  _2 = (_0).forward(_1, )\n",
            "  _3 = torch.tanh(torch.add(_1, h, alpha=1))\n",
            "  return (_3, _3)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh4-5wWg5ij4"
      },
      "source": [
        "``.code``の出力をご覧ください。if-else文が見当たりません。\n",
        "\n",
        "なぜでしょうか。\n",
        "\n",
        "<br>\n",
        "\n",
        "トレースは実際にコードが実行された通りに、その操作を記録し、TorchScriptのScriptModuleを生成します。\n",
        "\n",
        "そのため残念ながら、制御部分（control flow）は考慮できません。\n",
        "\n",
        "それではTorchScriptにcotrol flowを盛り込むにはどうすれば良いのでしょうか。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RIFgfwtKMKe"
      },
      "source": [
        "ここで、PythonのソースコードをTorchScriptへと解析、変換する**script compiler**（スクリプト・コンパイラ）を使用します。\r\n",
        "\r\n",
        "``MyDecisionGate``クラスを変換してみましょう。\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSaaU2LB5ij4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986a80e4-c18f-4734-8a4d-e82e6c83acda"
      },
      "source": [
        "scripted_gate = torch.jit.script(MyDecisionGate())\n",
        "\n",
        "my_cell = MyCell(scripted_gate)\n",
        "traced_cell = torch.jit.script(my_cell)\n",
        "print(traced_cell.code)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def forward(self,\n",
            "    x: Tensor,\n",
            "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
            "  _0 = (self.dg).forward((self.linear).forward(x, ), )\n",
            "  new_h = torch.tanh(torch.add(_0, h, alpha=1))\n",
            "  return (new_h, new_h)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQY-18T0Tgsy"
      },
      "source": [
        "（日本語訳注）\n",
        "\n",
        "上記では（self.dg）という部分が出力に含まれており、それがcontrol flowになっています。\n",
        "\n",
        "ですが、分かりづらいので、一応、TorchScrpitになったscripted_gateを確認しておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOfwavxRTYj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821473f6-100f-45e1-b783-3451c0826327"
      },
      "source": [
        "# 日本語版追記 TorchScriptにif文が入っていることが分かります\n",
        "print(scripted_gate.code)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def forward(self,\n",
            "    x: Tensor) -> Tensor:\n",
            "  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))\n",
            "  if _0:\n",
            "    _1 = x\n",
            "  else:\n",
            "    _1 = torch.neg(x)\n",
            "  return _1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBeTy49k5ij7"
      },
      "source": [
        "これで、うまくいきました。\n",
        "\n",
        "以上により、TorchScriptにcontrol flowを組み込めたので、実際に実行してみます。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TCQvO4M5ij7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4157673-f97b-44e8-b6f8-b97473811c12"
      },
      "source": [
        "# New inputs\n",
        "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
        "traced_cell(x, h)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.5665,  0.3799,  0.7255, -0.0325],\n",
              "         [ 0.8528,  0.5922,  0.7562, -0.0273],\n",
              "         [ 0.1272,  0.2416,  0.7779,  0.7921]], grad_fn=<TanhBackward>),\n",
              " tensor([[ 0.5665,  0.3799,  0.7255, -0.0325],\n",
              "         [ 0.8528,  0.5922,  0.7562, -0.0273],\n",
              "         [ 0.1272,  0.2416,  0.7779,  0.7921]], grad_fn=<TanhBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7zblMOj5ij-"
      },
      "source": [
        "**ScrptingとTracingを同時に使用する方法**\n",
        "\n",
        "ときに、PyTorchのモジュールが複雑であり、control flowが多様で、トレース（tracing）ではなくスクリプト（scripting）で変換したい場合があります。\n",
        "\n",
        "このような場合には、``torch.jit.script`をインラインで使用することで、モジュールのトレーシングと同時に使用することができます。\n",
        "\n",
        "最初の例を見てみましょう。\n",
        "\n",
        "（``torch.jit.trace``がインラインで使われた後、scriptしています）\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pSXDtHL5ij-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da97af8-bad7-4be6-c82c-5a1a50f46fe3"
      },
      "source": [
        "class MyRNNLoop(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyRNNLoop, self).__init__()\n",
        "        self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h))\n",
        "\n",
        "    def forward(self, xs):\n",
        "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
        "        for i in range(xs.size(0)):\n",
        "            y, h = self.cell(xs[i], h)\n",
        "        return y, h\n",
        "\n",
        "rnn_loop = torch.jit.script(MyRNNLoop())\n",
        "print(rnn_loop.code)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def forward(self,\n",
            "    xs: Tensor) -> Tuple[Tensor, Tensor]:\n",
            "  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n",
            "  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n",
            "  y0 = y\n",
            "  h0 = h\n",
            "  for i in range(torch.size(xs, 0)):\n",
            "    _0 = (self.cell).forward(torch.select(xs, 0, i), h0, )\n",
            "    y1, h1, = _0\n",
            "    y0, h0 = y1, h1\n",
            "  return (y0, h0)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ht6ax8J5ikA"
      },
      "source": [
        "次の例を確認してみましょう。\n",
        "\n",
        "（上記コードのクラスMyRNNLoopを``torch.jit.script``のインラインで使用）\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjrJR7SF5ikA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f902e012-5062-46d7-e93b-a8a134f1f143"
      },
      "source": [
        "class WrapRNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WrapRNN, self).__init__()\n",
        "        self.loop = torch.jit.script(MyRNNLoop())\n",
        "\n",
        "    def forward(self, xs):\n",
        "        y, h = self.loop(xs)\n",
        "        return torch.relu(y)\n",
        "\n",
        "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
        "print(traced.code)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def forward(self,\n",
            "    argument_1: Tensor) -> Tensor:\n",
            "  _0, h, = (self.loop).forward(argument_1, )\n",
            "  return torch.relu(h)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOIx8yHyWAan"
      },
      "source": [
        "このように、スクリプト（scripting）とトレース（tracing）は、どちらかからどちらかのTorchScriptを呼び出したり、同時に使用したりできます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgX-cARA5ikC"
      },
      "source": [
        "TorchScriptでのモデルの保存とロード\n",
        "-------------------------\n",
        "\n",
        "最後に、TorchScriptのモジュールを、ディスクにアーカイブフォーマット（archive format）で保存、ロードする関数（API）を解説します。\n",
        "\n",
        "このフォーマットには、コード、パラメータ、属性、およびデバッグ情報が含まれており、アーカイブフォーマットは、完全に別のプロセスでロードできる独立した表現手法です。\n",
        "\n",
        "さきほどのRNNモデルを保存、ロードしてみましょう。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Kk08tk5ikD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2510fd32-7d90-40a0-a02b-d950821c2a46"
      },
      "source": [
        "traced.save('wrapped_rnn.zip')\n",
        "\n",
        "loaded = torch.jit.load('wrapped_rnn.zip')\n",
        "\n",
        "print(loaded)\n",
        "print(loaded.code)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RecursiveScriptModule(\n",
            "  original_name=WrapRNN\n",
            "  (loop): RecursiveScriptModule(\n",
            "    original_name=MyRNNLoop\n",
            "    (cell): RecursiveScriptModule(\n",
            "      original_name=MyCell\n",
            "      (dg): RecursiveScriptModule(original_name=MyDecisionGate)\n",
            "      (linear): RecursiveScriptModule(original_name=Linear)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "def forward(self,\n",
            "    argument_1: Tensor) -> Tensor:\n",
            "  _0, h, = (self.loop).forward(argument_1, )\n",
            "  return torch.relu(h)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab4tQ9d_5ikF"
      },
      "source": [
        "ご覧の通り、変換は元のモジュールの構造を保っており、実行可能です。\n",
        "\n",
        "このモデルはPythonの実行環境に限らず例えば、C++実行環境でもロードすることができます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7em8Who3X4Qk"
      },
      "source": [
        "**さらなる発展へ**\n",
        "\n",
        "以上で本チュートリアルは終了です。\n",
        "\n",
        "<br>\n",
        "\n",
        "さらなるサンプル例としては、\n",
        "\n",
        "「NeurIPS demo for converting machine translation models using\n",
        "TorchScript」\n",
        "\n",
        "のGoogle Colabコードもぜひご覧ください。\n",
        "\n",
        "https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ\n",
        "\n",
        "\n"
      ]
    }
  ]
}