{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "6_9_combining_distributed_dataparallel_with_distributed_rpc_framework_jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV7vRIXaEQ-n"
      },
      "source": [
        "# 「分散データ並列と分散RPCフレームワークの連携」\n",
        "\n",
        "【原題】Combining Distributed DataParallel with Distributed RPC Framework\n",
        "\n",
        "【原著】[Pritam Damania](https://github.com/pritamdamania87)\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/advanced/rpc_ddp_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID HCM事業部　櫻井 亮佑\n",
        "\n",
        "【日付】2020年12月10日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "本チュートリアルではシンプルな例に対して、 [DistributedDataParallel](https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel)（DDP）と[分散RPCフレームワーク](https://pytorch.org/docs/master/rpc.html)の両方を利用し、分散データ並列化と分散モデル並列化を連携させて訓練する方法を解説します。<br>\n",
        "なお、本チュートリアルで使用しているコードは、 [こちら](https://github.com/pytorch/examples/tree/master/distributed/rpc/ddp_rpc)から確認できます。\n",
        "\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQHCB_EbEQ-z"
      },
      "source": [
        "ここまでのチュートリアルである [分散データ並列訓練入門](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)（日本語版6_3） と [分散RPCフレームワーク入門](https://pytorch.org/tutorials/intermediate/rpc_tutorial.html) （日本語版6_5）では、分散データ並列と分散モデル並列訓練をそれぞれ個別に実施する方法について解説しました。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWJXTR77ylv6"
      },
      "source": [
        "しかし、これら2つのテクニックを組み合わせたくなるような訓練パラダイムも存在します。例えば、以下のようなケースです。\r\n",
        "\r\n",
        "1. 疎な部分（大規模な埋め込みテーブル）と密な部分（FC層）を伴うモデルを扱う場合、埋め込みテーブルをパラメーターサーバー上に配置し、[DistributedDataParallel](https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel) を使ってFC層を複数のトレーナーに渡って複製したくなるかもしれません。この場合、パラメーターサーバー上で埋め込みの参照を行う際に、[分散RPCフレームワーク](https://pytorch.org/docs/master/rpc.html) が使用できます。\r\n",
        "\r\n",
        "\r\n",
        "2. [PipeDream](https://arxiv.org/abs/1806.03377) の論文にあるハイブリッド並列化を実現します。[分散RPCフレームワーク](https://pytorch.org/docs/master/rpc.html) を使用してモデルのステージを複数ワーカーに渡ってパイプライン化し、（必要であれば）[DistributedDataParallel](https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel) によって各ステージを複製することが可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoO_uFLcEQ-0"
      },
      "source": [
        "本チュートリアルでは、上記に掲載したケースのうち、1番目を扱います。\n",
        "\n",
        "今回の構成では、以下に示す計4つのワーカーを使用します。\n",
        "\n",
        "1. マスター。パラメーターサーバー上で埋め込みテーブル（nn.EmbeddingBag）を作成する役目を持ちます。また、マスターは2つのトレーナー上で訓練ループを主導します。\n",
        "\n",
        "2. パラメーターサーバー。基本的にはメモリ内で埋め込みテーブルを保持し、マスターとトレーナーからのRPCに応答します。\n",
        "\n",
        "3. 2つのトレーナー。 [DistributedDataParallel](https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel) を使い、2つのトレーナー間で複製されるFC層（nn.Linear）を格納します。またトレーナーは、フォワードパス、バックワードパス、そしてオプティマイザーステップを実行する役割も担います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4lf2LXmEQ-1"
      },
      "source": [
        "そして、訓練プロセス全体は以下のように実行されます。\n",
        "\n",
        "1. マスターがパラメーターサーバー上に埋め込みテーブルを作成し、この埋め込みテーブルへの [RRef](https://pytorch.org/docs/master/rpc.html#rref) を保持します。\n",
        "\n",
        "2. マスターがトレーナーに訓練ループを開始させ、埋め込みテーブルのRRefをトレーナーに渡します。\n",
        "\n",
        "3. 2つのトレーナーが、マスターから渡された埋め込みテーブルのRRefを使用して、埋め込みの参照を行う `HybridModel` を初めに作成し、その後DDPの内部にラップされているFC層を実行します。\n",
        "\n",
        "4. トレーナーがモデルのフォワードパスを実行し、[分散自動微分](https://pytorch.org/docs/master/rpc.html#distributed-autograd-framework) を使って、損失をもとに誤差逆伝搬を実行します。\n",
        "\n",
        "5. 誤差逆伝搬の内部処理として、FC層の勾配が初めに計算され、DDP内のallreduceを通してすべての訓練トレーナーに同期されます。\n",
        "\n",
        "6. 分散自動微分が勾配情報をパラメーターサーバーに渡し、パラメーターサーバー上で埋め込みテーブルの勾配が更新されます。\n",
        "\n",
        "7. 最後に、[分散オプティマイザー](https://pytorch.org/docs/master/rpc.html#module-torch.distributed.optim) を使用して、すべてのパラメーターを更新します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5JjMe-_EQ-1"
      },
      "source": [
        "**・注意**<br>\n",
        "DDPとRPCを組み合わせる場合、バックワードパス（誤差逆伝搬）では常に、[分散自動微分](https://pytorch.org/docs/master/rpc.html#distributed-autograd-framework) を使用するべきです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFj-AQBREQ-2"
      },
      "source": [
        "では、各パートの詳細を解説します。\n",
        "\n",
        "訓練を行う前に、今回使用するすべてのワーカーを初めに準備する必要があります。\n",
        "\n",
        "4つのプロセスを作成し、ランク0とランク1をトレーナー、ランク2をマスター、そしてランク3をパラメーターサーバーとします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkPoTeCFEQ-2"
      },
      "source": [
        "TCPの init_method を使用して、4つのワーカー上すべてでRPCフレームワークを初期化します。\n",
        "\n",
        "\n",
        "RPCの初期化完了後、マスターは [rpc.remote](https://pytorch.org/docs/master/rpc.html#torch.distributed.rpc.remote) を使用してパラメーターサーバー上に [EmbeddingBag](https://pytorch.org/docs/master/generated/torch.nn.EmbeddingBag.html) を作成します。\n",
        "\n",
        "\n",
        "そしてマスターは、各トレーナーをループし、[rpc_async](https://pytorch.org/docs/master/rpc.html#torch.distributed.rpc.rpc_async) により各トレーナー上で `_run_trainer` を呼び出し、訓練ループを開始します。\n",
        "\n",
        "最後に、マスターは離脱前にすべての訓練が終了するまで待機します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL_jRuazEQ-3"
      },
      "source": [
        "トレーナーは初めに、[init_process_group](https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group) を使用し、world_size=2（2つのトレーナー用）でDDPのための `ProcessGroup` を初期化します。\n",
        "\n",
        "次に、トレーナーはTCPの `init_method` を使用してRPCフレームワークを初期化します。\n",
        "\n",
        "なお、RPCの初期化と`ProcessGroup`の初期化処理でぽポートが異なる点に注意してください。\n",
        "\n",
        "これは、両フレームワークの初期化処理の間でポートの競合が発生することを防ぐためです。\n",
        "\n",
        "初期化が完了した後は、トレーナーはただマスターから来る `_run_trainer` のRPCを待機するだけです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCpjah2AEQ-3"
      },
      "source": [
        "パラメーターサーバーは、RPCフレームワークを初期化し、トレーナーとマスターからのRPCを待機するのみです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsXbQfwCEQ-4"
      },
      "source": [
        "def run_worker(rank, world_size):\n",
        "    r\"\"\"\n",
        "    RPCを初期化するラッパー関数。\n",
        "    関数を呼び出し、RPCを停止します。\n",
        "    \"\"\"\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '29500'\n",
        "\n",
        "\n",
        "    rpc_backend_options = TensorPipeRpcBackendOptions()\n",
        "    rpc_backend_options.init_method='tcp://localhost:29501'\n",
        "\n",
        "    # ランク2はmaster、ランク3はps、ランク0とランク1はトレーナーです。\n",
        "    if rank == 2:\n",
        "        rpc.init_rpc(\n",
        "                \"master\",\n",
        "                rank=rank,\n",
        "                world_size=world_size,\n",
        "                rpc_backend_options=rpc_backend_options)\n",
        "\n",
        "        # ps上に埋め込みテーブルを構築します。\n",
        "        emb_rref = rpc.remote(\n",
        "                \"ps\",\n",
        "                torch.nn.EmbeddingBag,\n",
        "                args=(NUM_EMBEDDINGS, EMBEDDING_DIM),\n",
        "                kwargs={\"mode\": \"sum\"})\n",
        "\n",
        "        # 2つのトレーナー上で訓練ループを実行します。\n",
        "        futs = []\n",
        "        for trainer_rank in [0, 1]:\n",
        "            trainer_name = \"trainer{}\".format(trainer_rank)\n",
        "            fut = rpc.rpc_async(\n",
        "                    trainer_name, _run_trainer, args=(emb_rref, rank))\n",
        "            futs.append(fut)\n",
        "\n",
        "        # すべての訓練が終了するまで待機します。\n",
        "        for fut in futs:\n",
        "            fut.wait()\n",
        "    elif rank <= 1:\n",
        "        # 2つのトレーナー上で分散データ並列を行うため、プロセスグループを初期化します。\n",
        "        dist.init_process_group(\n",
        "                backend=\"gloo\", rank=rank, world_size=2)\n",
        "\n",
        "        # RPCを初期化します。\n",
        "        trainer_name = \"trainer{}\".format(rank)\n",
        "        rpc.init_rpc(\n",
        "                trainer_name,\n",
        "                rank=rank,\n",
        "                world_size=world_size,\n",
        "                rpc_backend_options=rpc_backend_options)\n",
        "\n",
        "        # トレーナーはマスターからのRPCを待機します。\n",
        "    else:\n",
        "        rpc.init_rpc(\n",
        "                \"ps\",\n",
        "                rank=rank,\n",
        "                world_size=world_size,\n",
        "                rpc_backend_options=rpc_backend_options)\n",
        "        # パラメーターサーバーは特に何も処理を行いません。\n",
        "        pass\n",
        "\n",
        "    # すべてのrpcが終了するまで、ブロックします。\n",
        "    rpc.shutdown()\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # 2つのトレーナー、1つのパラメーターサーバー、1つのマスターです。\n",
        "    world_size = 4\n",
        "    mp.spawn(run_worker, args=(world_size, ), nprocs=world_size, join=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSVUqZ57EQ-5"
      },
      "source": [
        "Trainerの詳細について解説する前に、トレーナーが使用する `HybridModel` の紹介しましす。\n",
        "\n",
        "下記に示すように、`HybridModel` は、パラメーターサーバー上の埋め込みテーブル（`emb_rref`）のRRefとDDPに使用する `device` を用いて初期化されます。\n",
        "\n",
        "モデルの初期化処理では、複製するためにDDP内の [nn.Linear](https://pytorch.org/docs/master/generated/torch.nn.Linear.html) 層をラップし、ラップしたこの線形層をすべてのトレーナー間で同期するようにします。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtUcBoO8EQ-6"
      },
      "source": [
        "モデルのフォワードメソッドはとてもシンプルです。\n",
        "\n",
        "[RRefのヘルパー関数](https://pytorch.org/docs/master/rpc.html#torch.distributed.rpc.RRef.rpc_sync) を使用してパラメーターサーバー上の埋め込みの参照を行い、得られた出力をFC層に渡します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDMVbcc5EQ-6"
      },
      "source": [
        "class HybridModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    モデルは、疎な部分と密な部分で構成されています。\n",
        "    密な部分は、分散データ並列を用いてすべてのトレーナー上に複製される nn.Linear モジュールです。\n",
        "    疎な部分は、パラメーターサーバー上に格納されている nn.EmbeddingBag です。\n",
        "    \n",
        "    モデルは、パラメーターサーバー上の埋め込みテーブルへのリモート参照を保持しています。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emb_rref, device):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.emb_rref = emb_rref\n",
        "        self.fc = DDP(torch.nn.Linear(16, 8).cuda(device), device_ids=[device])\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, indices, offsets):\n",
        "        emb_lookup = self.emb_rref.rpc_sync().forward(indices, offsets)\n",
        "        return self.fc(emb_lookup.cuda(self.device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lScZ8LCQEQ-7"
      },
      "source": [
        "次に、Trainerでのセットアップを確認しましょう。\n",
        "\n",
        "\n",
        "トレーナーは、パラメーターサーバー上の埋め込みテーブルへのRRefと自身のランクを使用して、上掲の `HybridModel` を初めに作成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Nk5ZZjEQ-7"
      },
      "source": [
        "そして、[DistributedOptimizer](https://pytorch.org/docs/master/rpc.html#module-torch.distributed.optim) で最適化したいすべてのパラメーターへのRRefのリストを回収する必要があります。\n",
        "\n",
        "パラメーターサーバーから埋め込みテーブルのパラメーターを回収するために、`_retrieve_embedding_parameters` という単純な関数を定義します。\n",
        "\n",
        "この関数は、基本的には埋め込みテーブルのすべてのパラメーターを走査し、RRefのリストを返します。\n",
        "\n",
        "トレーナーはパラメーターサーバー上のこのメソッドをRPC経由で呼び出し、必要なパラメーターへのRRefのリストを回収します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLNfuEt90XeF"
      },
      "source": [
        "また、`DistributedOptimizer` は、最適化される必要のあるパラメーターへのRRefのリストを常に引数に取るため、FC層のために、ローカルパラメーターであってもRRefを作成しなければいけません。\r\n",
        "\r\n",
        "これは、`model.parameters()` を走査して各パラメーターへのRRefを作成し、リストに追加することで行なえます。\r\n",
        "\r\n",
        "なお、`model.parameters()` はローカルパラメーターのみを返し、`emb_rref` は返り値に含まれていない点に注意してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tw3VbeMEQ-7"
      },
      "source": [
        "最後に、すべてのRRefを使用して `DistributedOptimizer` を作成し、`CrossEntropyLoss` 関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo_rfaHgEQ-8"
      },
      "source": [
        "def _retrieve_embedding_parameters(emb_rref):\n",
        "    param_rrefs = []\n",
        "    for param in emb_rref.local_value().parameters():\n",
        "        param_rrefs.append(RRef(param))\n",
        "    return param_rrefs\n",
        "\n",
        "\n",
        "def _run_trainer(emb_rref, rank):\n",
        "    r\"\"\"\n",
        "    各トレーナーは、パラメーターサーバー上の埋め込みの参照と\n",
        "    ローカルでの nn.Linear の実行を含むフォワードパスを実行します。\n",
        "    バックワードパスの間は、DDPが密な部分（nn.Linear）の勾配の集約の役割を担い、\n",
        "    分散自動微分が、勾配の更新がパラメーターサーバーに伝播されるように担保しています。\n",
        "    \"\"\"\n",
        "\n",
        "    # モデルをセットアップします。\n",
        "    model = HybridModel(emb_rref, rank)\n",
        "\n",
        "    # DistributedOptimizer のために rref である モデルのすべてのパラメーターを回収します。\n",
        "\n",
        "    # 埋め込みテーブル用にパラメーターを回収します。\n",
        "    model_parameter_rrefs = rpc.rpc_sync(\n",
        "            \"ps\", _retrieve_embedding_parameters, args=(emb_rref,))\n",
        "\n",
        "    # model.parameters() は、ローカルパラメーターのみを含んでいます。\n",
        "    for param in model.parameters():\n",
        "        model_parameter_rrefs.append(RRef(param))\n",
        "\n",
        "    # 分散オプティマイザーをセットアップします。\n",
        "    opt = DistributedOptimizer(\n",
        "        optim.SGD,\n",
        "        model_parameter_rrefs,\n",
        "        lr=0.05,\n",
        "    )\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuKKQjXZEQ-8"
      },
      "source": [
        "各トレーナー上で実行する訓練ループを導入する準備ができました。\n",
        "\n",
        "`get_next_batch` は、訓練用にランダムな入力とターゲットを生成する補助関数（ヘルパー関数）です。\n",
        "\n",
        "そして、訓練ループを複数エポック実行します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDkXyiTr0kNo"
      },
      "source": [
        "各バッチでは以下の処理を行います。\r\n",
        "\r\n",
        "1. 分散自動微分のために [分散自動微分コンテクスト](https://pytorch.org/docs/master/rpc.html#torch.distributed.autograd.context) をセットアップします。\r\n",
        "\r\n",
        "2. モデルのフォワードパスを実行し、出力を取得します。\r\n",
        "\r\n",
        "3. 取得した出力とターゲットを基に、損失関数を用いて損失を計算します。\r\n",
        "\r\n",
        "4. 損失を使用して、分散自動微分により分散バックワードパスを実行します。\r\n",
        "\r\n",
        "5. 最後に、分散オプティマイザーでステップを実行し、すべてのパラメーターを最適化します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSMET1EWEQ-9"
      },
      "source": [
        "    def get_next_batch(rank):\n",
        "        for _ in range(10):\n",
        "            num_indices = random.randint(20, 50)\n",
        "            indices = torch.LongTensor(num_indices).random_(0, NUM_EMBEDDINGS)\n",
        "\n",
        "            # オフセットの生成\n",
        "            offsets = []\n",
        "            start = 0\n",
        "            batch_size = 0\n",
        "            while start < num_indices:\n",
        "                offsets.append(start)\n",
        "                start += random.randint(1, 10)\n",
        "                batch_size += 1\n",
        "\n",
        "            offsets_tensor = torch.LongTensor(offsets)\n",
        "            target = torch.LongTensor(batch_size).random_(8).cuda(rank)\n",
        "            yield indices, offsets_tensor, target\n",
        "\n",
        "    # 100エポックの訓練\n",
        "    for epoch in range(100):\n",
        "        # 分散自動微分コンテクストの作成\n",
        "        for indices, offsets, target in get_next_batch(rank):\n",
        "            with dist_autograd.context() as context_id:\n",
        "                output = model(indices, offsets)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "                # 分散バックワードパスの実行\n",
        "                dist_autograd.backward(context_id, [loss])\n",
        "\n",
        "                # 分散オプティマイザーの実行\n",
        "                opt.step(context_id)\n",
        "\n",
        "                # 各イテレーションで、別の勾配を管理する異なる分散自動微分コンテクストを作成するため、\n",
        "                # 勾配をゼロ化する必要はありません。\n",
        "        print(\"Training done for epoch {}\".format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bjk9qWSEQ-9"
      },
      "source": [
        "以上となります。サンプルのソースコードの全体は、[こちら](https://github.com/pytorch/examples/tree/master/distributed/rpc/ddp_rpc)から確認できます。"
      ]
    }
  ]
}