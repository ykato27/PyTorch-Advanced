{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "6_7_distributed_pipeline_parallelism_using_rpc_jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLRyd3CXZ7HK"
      },
      "source": [
        "# 「RPCを用いた分散パイプライン並列化」\n",
        "\n",
        "【原題】Distributed Pipeline Parallelism Using RPC\n",
        "\n",
        "【原著】[Shen Li](https://mrshenli.github.io/)\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/intermediate/dist_pipeline_parallel_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID HCM事業部　櫻井 亮佑\n",
        "\n",
        "【日付】2020年12月04日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "前提知識\n",
        "- [PyTorch Distributedの概要](https://pytorch.org/tutorials/beginner/dist_overview.html)（日本語版6_1）\n",
        "- [シングルマシン環境におけるモデル並列訓練](https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html)（日本語版6_2）\n",
        "- [分散RPCフレームワーク入門](https://pytorch.org/tutorials/intermediate/rpc_tutorial.html)（日本語版6_5）\n",
        "- RRefで役に立つ関数：[RRef.rpc_sync()](https://pytorch.org/docs/master/rpc.html#torch.distributed.rpc.RRef.rpc_sync)、[RRef.rpc_async()](https://pytorch.org/docs/master/rpc.html#torch.distributed.rpc.RRef.rpc_async)、及び [RRef.remote()](https://pytorch.org/docs/master/rpc.html#torch.distributed.rpc.RRef.remote)\n",
        "\n",
        "<br>\n",
        "\n",
        "本チュートリアルでは、Resnet50のモデルに対して、[torch.distributed.rpc](https://pytorch.org/docs/master/rpc.html) APIで分散パイプライン並列化を実装する方法を解説します。\n",
        "\n",
        "なお分散パイプライン並列化は、[シングルマシン環境におけるモデル並列訓練](https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html)で解説したマルチGPUのパイプラインが並列分散化した内容と捉えることが可能です。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yUCCQmkZ7HT"
      },
      "source": [
        "**注意**\n",
        "\n",
        "- 本チュートリアルにはPyTorch v1.6.0以上が必要になります。\n",
        "\n",
        "- 本チュートリアルのソースコードは、[pytorch/examplesのこちら](https://github.com/pytorch/examples/tree/master/distributed/rpc/pipeline) にて確認できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqYnFgFFZ7HT"
      },
      "source": [
        "## はじめに\n",
        "\n",
        "2つ前のチュートリアル、[分散RPCフレームワーク入門](https://pytorch.org/tutorials/intermediate/rpc_tutorial.html)（日本語版6_5） では、`torch.distributed.rpc` を使い、分散モデル並列化を行ってRNNモデルを実装する方法を示しました。\n",
        "\n",
        "その際は、一つのGPUで `EmbeddingTable` を管理してコードを正常に動作させていました。\n",
        "\n",
        "しかし、モデルが複数のGPUに存在する場合には、すべてのGPUの稼働率を増やすため、もう少し手順が必要になります。\n",
        "\n",
        "パイプライン並列化は、このようなケースにおいて役立つ枠組みの一つとなります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0OohEORZ7HU"
      },
      "source": [
        "本チュートリアルでは、[シングルマシン環境におけるモデル並列訓練](https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html)（日本語版6_2） のチュートリアルでも使用された `ResNet50` を例に使用します。\n",
        "\n",
        "また同様に、ResNet50 のモデルを2片に分割し、入力バッチも複数の固まりに分けた上で、パイプライン化された手法で2片のモデルに与えます。\n",
        "\n",
        "「シングルマシン環境におけるモデル並列訓練」で示した手法との違いは、CUDAのストリームを用いて実行を並列化する代わりに、本チュートリアルでは非同期RPCを呼び出している点です。\n",
        "\n",
        "そのため、本チュートリアルで解説する内容は、コンピューティング・マシンの境界を超えても動作します。\n",
        "\n",
        "これから4つのステップで、実装方法を解説します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysAZ9f4iZ7HU"
      },
      "source": [
        "## Step 1: ResNet50 モデルの分割\n",
        "\n",
        "始めに、モデルを分割した状態で、 `ResNet50` を実装する準備段階を行います。\n",
        "\n",
        "\n",
        "下記のコードは、[torchvisionのResNetの実装](https://github.com/pytorch/vision/blob/7c077f6a986f05383bcb86b535aedb5a63dd5c4b/torchvision/models/resnet.py#L124)から借用しています。\n",
        "\n",
        "`ResNetBase` モジュールは、分割された2片のResNetに共通する構成要素と属性変数を含んでいます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sExfF-v0Z7HU"
      },
      "source": [
        "import threading\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.models.resnet import Bottleneck\n",
        "\n",
        "num_classes = 1000\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class ResNetBase(nn.Module):\n",
        "    def __init__(self, block, inplanes, num_classes=1000,\n",
        "                groups=1, width_per_group=64, norm_layer=None):\n",
        "        super(ResNetBase, self).__init__()\n",
        "\n",
        "        self._lock = threading.Lock()\n",
        "        self._block = block\n",
        "        self._norm_layer = nn.BatchNorm2d\n",
        "        self.inplanes = inplanes\n",
        "        self.dilation = 1\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "\n",
        "    def _make_layer(self, planes, blocks, stride=1):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if stride != 1 or self.inplanes != planes * self._block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * self._block.expansion, stride),\n",
        "                norm_layer(planes * self._block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(self._block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                                self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * self._block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(self._block(self.inplanes, planes, groups=self.groups,\n",
        "                                    base_width=self.base_width, dilation=self.dilation,\n",
        "                                    norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def parameter_rrefs(self):\n",
        "        return [RRef(p) for p in self.parameters()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRxHnOMoZ7HV"
      },
      "source": [
        "これでモデルを定義する準備ができました。\n",
        "\n",
        "以下で実装します。\n",
        "\n",
        "以下のコンストラクターでは、すべてのResNet50の層を2つの部分に分け、それぞれの部分を所与のデバイスに移動しているだけです。\n",
        "\n",
        "どちらのモデル片の `forward` 関数も、入力データのRRefを引数に取り、データをローカルで与え、その後目的のデバイスに移動させています。\n",
        "\n",
        "そして、すべての層を入力に適用した後は、出力をCPUに移して返しています。\n",
        "\n",
        "これは、呼び出し元と呼び出し先でデバイスの数が一致していない場合のデバイスエラーを避ける目的で、”テンソルがCPU上に存在すること”をRPC APIが必要としているために必要な操作となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnHkJOLrZ7HV"
      },
      "source": [
        "class ResNetShard1(ResNetBase):\n",
        "    def __init__(self, device, *args, **kwargs):\n",
        "        super(ResNetShard1, self).__init__(\n",
        "            Bottleneck, 64, num_classes=num_classes, *args, **kwargs)\n",
        "\n",
        "        self.device = device\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            self._norm_layer(self.inplanes),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            self._make_layer(64, 3),\n",
        "            self._make_layer(128, 4, stride=2)\n",
        "        ).to(self.device)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x_rref):\n",
        "        x = x_rref.to_here().to(self.device)\n",
        "        with self._lock:\n",
        "            out =  self.seq(x)\n",
        "        return out.cpu()\n",
        "\n",
        "\n",
        "class ResNetShard2(ResNetBase):\n",
        "    def __init__(self, device, *args, **kwargs):\n",
        "        super(ResNetShard2, self).__init__(\n",
        "            Bottleneck, 512, num_classes=num_classes, *args, **kwargs)\n",
        "\n",
        "        self.device = device\n",
        "        self.seq = nn.Sequential(\n",
        "            self._make_layer(256, 6, stride=2),\n",
        "            self._make_layer(512, 3, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.fc =  nn.Linear(512 * self._block.expansion, num_classes).to(self.device)\n",
        "\n",
        "    def forward(self, x_rref):\n",
        "        x = x_rref.to_here().to(self.device)\n",
        "        with self._lock:\n",
        "            out = self.fc(torch.flatten(self.seq(x), 1))\n",
        "        return out.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlTQFrueZ7HW"
      },
      "source": [
        "## Step 2: ResNet50のモデル片を一つのモジュールへ\n",
        "\n",
        "次に、2片のモデルを結合して `DistResNet50` モジュールを作成し、パイプライン並列のロジックを実装します。\n",
        "\n",
        "コンストラクターでは、2つの `rpc.remote` を呼び出し、2片のモデルをそれぞれ異なるRPCのワーカー上に配置します。\n",
        "\n",
        "そして、フォワードパスで参照できるように、2つのモデルの部分へのRRefを保持しておきます。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0z7_AOnluHB"
      },
      "source": [
        "`forward`関数では、入力バッチを複数のマイクロバッチに分割し、これらのマイクロバッチをパイプライン化された方法で2つのモデルの部分に与えます。\r\n",
        "\r\n",
        "最初に、`rpc.remote` を呼び出して最初のモデル片をマイクロバッチに適用し、その後、返ってきた中間出力のRRefを2つ目のモデル片にフォワードします。\r\n",
        "\r\n",
        "そして、すべてのマイクロ出力の `Future` を集め、ループ後にすべての `Future` が完了するまで待機します。\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPI9Xh8rl343"
      },
      "source": [
        "なお、`remote()` と `rpc_async()`　は、返り値を即時に返し、非同期に処理を実行する点に注意してください。\r\n",
        "\r\n",
        "したがって、ループ全体でブロックは行われず、複数のRPCが同時に起動します。\r\n",
        "\r\n",
        "2つのモデルの部分における一つのマイクロバッチの実行順序は、中間出力 `y_rref` によって保持されています。\r\n",
        "\r\n",
        "なお、マイクロバッチ間での実行順序は問題になりません。\r\n",
        "\r\n",
        "最後に、`forward` 関数は、すべてのマイクロバッチの出力を単一の出力テンソルに結合して、値を返します。\r\n",
        "\r\n",
        "`parameter_rrefs` 関数は、分散オプティマイザーの構築を簡略化するための関数ですが、この関数は後ほど使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJJJ7f2_Z7HW"
      },
      "source": [
        "class DistResNet50(nn.Module):\n",
        "    def __init__(self, num_split, workers, *args, **kwargs):\n",
        "        super(DistResNet50, self).__init__()\n",
        "\n",
        "        self.num_split = num_split\n",
        "\n",
        "        # ResNet50の最初の部分を workers[0] に配置します。\n",
        "        self.p1_rref = rpc.remote(\n",
        "            workers[0],\n",
        "            ResNetShard1,\n",
        "            args = (\"cuda:0\",) + args,\n",
        "            kwargs = kwargs\n",
        "        )\n",
        "\n",
        "        # ResNet50の2つ目の部分を workers[1] に配置します。\n",
        "        self.p2_rref = rpc.remote(\n",
        "            workers[1],\n",
        "            ResNetShard2,\n",
        "            args = (\"cuda:1\",) + args,\n",
        "            kwargs = kwargs\n",
        "        )\n",
        "\n",
        "    def forward(self, xs):\n",
        "        out_futures = []\n",
        "        for x in iter(xs.split(self.split_size, dim=0)):\n",
        "            x_rref = RRef(x)\n",
        "            y_rref = self.p1_rref.remote().forward(x_rref)\n",
        "            z_fut = self.p2_rref.rpc_async().forward(y_rref)\n",
        "            out_futures.append(z_fut)\n",
        "\n",
        "        return torch.cat(torch.futures.wait_all(out_futures))\n",
        "\n",
        "    def parameter_rrefs(self):\n",
        "        remote_params = []\n",
        "        remote_params.extend(self.p1_rref.remote().parameter_rrefs().to_here())\n",
        "        remote_params.extend(self.p2_rref.remote().parameter_rrefs().to_here())\n",
        "        return remote_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb1mKn4kZ7HY"
      },
      "source": [
        "## Step 3: 訓練ループの定義\n",
        "\n",
        "モデルを定義した後は、訓練ループを実装しましょう。\n",
        "\n",
        "専用の\"マスター\"ワーカーを使用して、ランダムな入力とラベルを準備し、分散バックワードパスと分散オプティマイザーステップを制御します。\n",
        "\n",
        "最初に `DistResNet50` モジュールのインスタンスを作成します。\n",
        "\n",
        "`DistResNet50` のインスタンス化の際には、各バッチにおけるマイクロバッチの数を指定し、2つのRPCワーカーの名前（例：\"worker1\" と \"worker2\"）も渡します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMrvlsxOmIFE"
      },
      "source": [
        "そして、損失関数を定義し、`parameter_rrefs()` を使用してパラメーターの `RRef` のリストを取得した上で、 `DistributedOptimizer` を作成します。\r\n",
        "\r\n",
        "残りの部分は、`dist_autograd` を使用してバックワードを起動します。\r\n",
        "\r\n",
        "`context_id` をバックワードとオプティマイザーの`step()` の両方に渡している点を除けば、主な訓練ループの手順は、通常のローカルでの訓練と良く似た内容です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrwzIoxaZ7HY"
      },
      "source": [
        "import torch.distributed.autograd as dist_autograd\n",
        "import torch.optim as optim\n",
        "from torch.distributed.optim import DistributedOptimizer\n",
        "\n",
        "num_batches = 3\n",
        "batch_size = 120\n",
        "image_w = 128\n",
        "image_h = 128\n",
        "\n",
        "\n",
        "def run_master(num_split):\n",
        "    # 2つのモデルの部分を、それぞれ worker1 と worker2 に配置します。\n",
        "    model = DistResNet50(num_split, [\"worker1\", \"worker2\"])\n",
        "    loss_fn = nn.MSELoss()\n",
        "    opt = DistributedOptimizer(\n",
        "        optim.SGD,\n",
        "        model.parameter_rrefs(),\n",
        "        lr=0.05,\n",
        "    )\n",
        "\n",
        "    one_hot_indices = torch.LongTensor(batch_size) \\\n",
        "                        .random_(0, num_classes) \\\n",
        "                        .view(batch_size, 1)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        print(f\"Processing batch {i}\")\n",
        "        # ランダムな入力とラベルの生成\n",
        "        inputs = torch.randn(batch_size, 3, image_w, image_h)\n",
        "        labels = torch.zeros(batch_size, num_classes) \\\n",
        "                    .scatter_(1, one_hot_indices, 1)\n",
        "\n",
        "        with dist_autograd.context() as context_id:\n",
        "            outputs = model(inputs)\n",
        "            dist_autograd.backward(context_id, [loss_fn(outputs, labels)])\n",
        "            opt.step(context_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50qsitS8Z7HY"
      },
      "source": [
        "## Step 4: RPCプロセスの起動\n",
        "\n",
        "最後に、下記のコードはすべてのプロセスを対象にした関数を示しています。\n",
        "\n",
        "主なロジックは、`run_master` にて定義されています。\n",
        "\n",
        "なお、ワーカーは受動的にマスターからの指令を待機し、単に `init_rpc` と `shutdown` を実行しますが、この `shutdown` はデフォルト動作として、関わっているすべてのRPCが終了するまで処理を待ち、ブロックしてくれます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSlz_GNnZ7HZ"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "\n",
        "def run_worker(rank, world_size, num_split):\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '29500'\n",
        "    options = rpc.TensorPipeRpcBackendOptions(num_worker_threads=128)\n",
        "\n",
        "    if rank == 0:\n",
        "        rpc.init_rpc(\n",
        "            \"master\",\n",
        "            rank=rank,\n",
        "            world_size=world_size,\n",
        "            rpc_backend_options=options\n",
        "        )\n",
        "        run_master(num_split)\n",
        "    else:\n",
        "        rpc.init_rpc(\n",
        "            f\"worker{rank}\",\n",
        "            rank=rank,\n",
        "            world_size=world_size,\n",
        "            rpc_backend_options=options\n",
        "        )\n",
        "        pass\n",
        "\n",
        "    # すべての rpc が終了するまでブロック\n",
        "    rpc.shutdown()\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    world_size = 3\n",
        "    for num_split in [1, 2, 4, 8]:\n",
        "        tik = time.time()\n",
        "        mp.spawn(run_worker, args=(world_size, num_split), nprocs=world_size, join=True)\n",
        "        tok = time.time()\n",
        "        print(f\"number of splits = {num_split}, execution time = {tok - tik}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KETs45o1Z7Ha"
      },
      "source": [
        "下記の出力は、各バッチの分割数を増やすことで実現できる高速化を示しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwKQK5GbZ7Ha"
      },
      "source": [
        "```\n",
        "$ python main.py\n",
        "Processing batch 0\n",
        "Processing batch 1\n",
        "Processing batch 2\n",
        "number of splits = 1, execution time = 16.45062756538391\n",
        "Processing batch 0\n",
        "Processing batch 1\n",
        "Processing batch 2\n",
        "number of splits = 2, execution time = 12.329529762268066\n",
        "Processing batch 0\n",
        "Processing batch 1\n",
        "Processing batch 2\n",
        "number of splits = 4, execution time = 10.164430618286133\n",
        "Processing batch 0\n",
        "Processing batch 1\n",
        "Processing batch 2\n",
        "number of splits = 8, execution time = 9.076049566268921\n",
        "```"
      ]
    }
  ]
}