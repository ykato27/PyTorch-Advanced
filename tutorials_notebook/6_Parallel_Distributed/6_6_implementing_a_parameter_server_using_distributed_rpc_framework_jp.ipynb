{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "6_6_implementing_a_parameter_server_using_distributed_rpc_framework_jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TToWoY_EvoA"
      },
      "source": [
        "# 「分散RPCフレームワークを用いたパラメーターサーバーの実装」\n",
        "\n",
        "【原題】Implementing a Parameter Server Using Distributed RPC Framework\n",
        "\n",
        "【原著】[Rohan Varma](https://github.com/rohan-varma)\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/intermediate/rpc_param_server_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID HCM事業部　櫻井 亮佑\n",
        "\n",
        "【日付】2020年11月28日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "前提知識:\n",
        "- [PyTorch Distributedについて](https://pytorch.org/tutorials/beginner/dist_overview.html)（日本語版6_1）\n",
        "- [RPC APIドキュメント](https://pytorch.org/docs/master/rpc.html)\n",
        "\n",
        "\n",
        "本チュートリアルでは、PyTorchの[分散RPCフレームワーク](https://pytorch.org/docs/stable/rpc.html)を用いた、パラメーターサーバーの簡単な実装例を解説します。\n",
        "\n",
        "パラメーターサーバーフレームワークは、複数のサーバーが大規模な埋め込みテーブルなどのパラメーターを格納し、複数のトレーナーがパラメーターサーバに問い合わせることで、ほぼ最新のパラメータを取得することが出来るようにする枠組みです。\n",
        "\n",
        "これらのトレーナーは、ローカルで訓練ループを実行し、ときおりパラメーターサーバーと同期して、最新のパラメータを取得します。\n",
        "\n",
        "パラメーターサーバーを用いたアプローチ手法の詳細に関しては、[こちらの論文](https://www.cs.cmu.edu/~muli/file/parameter_server_osdi14.pdf) を確認してください。\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cckrf3yXEvoO"
      },
      "source": [
        "本チュートリアルでは、分散RPCフレームワークと共に、複数のトレーナーでRPCを使って同一のパラメーターサーバーに対して通信を行い、さらに[RRef](https://pytorch.org/docs/stable/rpc.html#torch.distributed.rpc.RRef)を使用してリモートのパラメーターサーバーのインスタンス状態にアクセスする例を構築します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sxFqUM9Xxqb"
      },
      "source": [
        "各トレーナーは、分散自動微分を使用して複数のノードにまたがる自動微分グラフを合わせることにより、分散した状態で専用のバックワードパスを使用するようにします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtxnlOmOEvoO"
      },
      "source": [
        "**注意:**\n",
        "\n",
        "本チュートリアルでは、モデルを複数のマシンに分割したり、ネットワークトレーナーが異なるマシン上で管理されているパラメーターを受け取れるような、パラメーターサーバーを用いた訓練手法を実装する際に役立つ、分散RPCフレームワークの使い方を網羅します。\n",
        "\n",
        "仮に、このようなケースではなく、モデルを多数のGPU上に複製する方法を探している場合は、[分散データ並列訓練入門](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html) （日本語版6_3）を参照してください。\n",
        "\n",
        "また、強化学習やRNNのユースケースを網羅した[RPCのチュートリアル](https://pytorch.org/tutorials/intermediate/rpc_tutorial.html) （日本語版6_5）も用意されています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Oh_pvuNEvoP"
      },
      "source": [
        "まずは馴染みのある部分から始めましょう。\n",
        "\n",
        "必要なモジュールをインポートし、MNISTのデータセット上で訓練を行うシンプルな畳み込みニューラルネットワークを定義します。\n",
        "\n",
        "なお、下記のネットワークの大部分は、[pytorch/examples のリポジトリ](https://github.com/pytorch/examples/tree/master/mnist)で定義されているものから借用しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjsJJqk0EvoP"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "from threading import Lock\n",
        "\n",
        "import torch\n",
        "import torch.distributed.autograd as dist_autograd\n",
        "import torch.distributed.rpc as rpc\n",
        "import torch.multiprocessing as mp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.distributed.optim import DistributedOptimizer\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# --------- pytorch/examplesより、訓練対象のMNISTネットワーク -----\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_gpus=0):\n",
        "        super(Net, self).__init__()\n",
        "        print(f\"Using {num_gpus} GPUs to train\")\n",
        "        self.num_gpus = num_gpus\n",
        "        device = torch.device(\n",
        "            \"cuda:0\" if torch.cuda.is_available() and self.num_gpus > 0 else \"cpu\")\n",
        "        print(f\"Putting first 2 convs on {str(device)}\")\n",
        "        # 畳み込み層を1つ目のcudaデバイスに配置します。cudaデバイスが存在しない場合、CPUに配置します。\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1).to(device)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1).to(device)\n",
        "        # 2つ目のcudaデバイスが存在する場合、残りのネットワークを2つ目のcudaデバイスに配置します。\n",
        "        if \"cuda\" in str(device) and num_gpus > 1:\n",
        "            device = torch.device(\"cuda:1\")\n",
        "\n",
        "        print(f\"Putting rest of layers on {str(device)}\")\n",
        "        self.dropout1 = nn.Dropout2d(0.25).to(device)\n",
        "        self.dropout2 = nn.Dropout2d(0.5).to(device)\n",
        "        self.fc1 = nn.Linear(9216, 128).to(device)\n",
        "        self.fc2 = nn.Linear(128, 10).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # 必要に応じて、テンソルを次のデバイスに移動します。\n",
        "        next_device = next(self.fc1.parameters()).device\n",
        "        x = x.to(next_device)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEEzGmnoEvoR"
      },
      "source": [
        "次に、残りのスクリプトで役に立つ補助関数を定義しましょう。\n",
        "\n",
        "次のコードでは、[rpc_sync](https://pytorch.org/docs/stable/rpc.html#torch.distributed.rpc.rpc_sync) と [RRef](https://pytorch.org/docs/stable/rpc.html#torch.distributed.rpc.RRef) を使用し、リモートノードに存在するオブジェクト上で任意のメソッドを呼び出す関数を定義しています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD96LeeaYz5G"
      },
      "source": [
        "また、2番目に定義している関数では、リモートオブジェクトへのハンドルを `rref` 引数で与え、その `rref` の所有ノード上でメソッドを実行します。（`rref.owner()`）\r\n",
        "\r\n",
        "なお、呼び出し元のノードでは、`rpc_sync` の使用を通してこれらの処理を同期的に実行するため、レスポンスを受け取るまでは処理をブロックする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRWCOAtKEvoS"
      },
      "source": [
        "# --------- Helper Methods --------------------\n",
        "\n",
        "# ローカルノード上では、最初の引数をRRefによって保有されている値としてメソッドを呼び出します。\n",
        "# そして他の引数は、関数を呼び出すために使用される引数として渡されます。\n",
        "# この関数はインスタンスメソッドを呼び出す際に役立ちます。\n",
        "# methodには、クラスメソッドを含む任意の適当な関数を渡すことが可能です。\n",
        "def call_method(method, rref, *args, **kwargs):\n",
        "    return method(rref.local_value(), *args, **kwargs)\n",
        "\n",
        "# RRefを引数に受け取り、このRRefが保有する値を基に実行したメソッドの結果を返します。\n",
        "# この呼出は、RRefを保有するリモートノード上で行われ、与えられた引数をメソッドに渡します。\n",
        "# 例：RRefが保有している値の型が Foo である場合、remote_method(Foo.bar, rref, arg1, arg2) は、\n",
        "#    <foo_instance>.bar(arg1, arg2)をリモートノード上で呼び出し、結果を取得していることと等価です。\n",
        "def remote_method(method, rref, *args, **kwargs):\n",
        "    args = [method, rref] + list(args)\n",
        "    return rpc.rpc_sync(rref.owner(), call_method, args=args, kwargs=kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igrKAPxjEvoT"
      },
      "source": [
        "これで、パラメーターサーバーを定義する準備ができました。\n",
        "\n",
        "nn.Moduleをサブクラス化し、上記で定義したネットワークへのハンドルを保存します。\n",
        "\n",
        "また、モデルを呼び出す前に、入力を移動する先として、使用するデバイスを入力デバイスとして保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGh3IgnxEvoT"
      },
      "source": [
        "# --------- Parameter Server --------------------\n",
        "class ParameterServer(nn.Module):\n",
        "    def __init__(self, num_gpus=0):\n",
        "        super().__init__()\n",
        "        model = Net(num_gpus=num_gpus)\n",
        "        self.model = model\n",
        "        self.input_device = torch.device(\n",
        "            \"cuda:0\" if torch.cuda.is_available() and num_gpus > 0 else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uSmyHLsEvoU"
      },
      "source": [
        "次に、フォワードパスを定義します。\n",
        "\n",
        "なお、現在のところDistributed RPC Frameworkは、RPC経由の場合にCPUのテンソルのみの送信をサポートしているため、モデルの出力のデバイスに関わらず、出力をCPUに移動する点に注意してください。\n",
        "\n",
        "呼び出し元と呼び出し先でデバイスが異なる（CPU/GPU）可能性を考慮して、今回は意図的にRPC経由でCUDAのテンソルを送信しないようにしますが、後のリリースでサポートされていることを願います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s0LsFjJEvoU"
      },
      "source": [
        "class ParameterServer(nn.Module):\n",
        "    # ...\n",
        "    def forward(self, inp):\n",
        "        inp = inp.to(self.input_device)\n",
        "        out = self.model(inp)\n",
        "        # この出力は、RPC経由でフォワードされますが、1.5.0の時点ではCPUのテンソルしか受け付けていません。\n",
        "        # そのため、テンソルをGPUのメモリに出し入れしなければなりません。\n",
        "        out = out.to(\"cpu\")\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv2tIxpREvoU"
      },
      "source": [
        "次に、訓練や検証に役立つ諸々の関数を定義していきます。\n",
        "\n",
        "1つ目は、`get_dist_gradients` 関数です。\n",
        "\n",
        "これは、分散自動微分のコンテクストID を基に `dist_autograd.get_gradients` API を呼び出し、分散自動微分エンジンによって計算された勾配を取得します。\n",
        "\n",
        "分散自動微分に関する詳細な情報は、[分散自動微分のドキュメント](https://pytorch.org/docs/stable/rpc.html#distributed-autograd-framework) で確認できます。\n",
        "\n",
        "なお、現在のところ、フレームワークはRPCを介したテンソルの送信のみをサポートしているため、 `dist_autograd.get_gradients` の実行結果として得られるdictオブジェクトを反復して、各テンソルからCPUテンソルへの変換も行っている点に注意してください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoVO1OcOZJHC"
      },
      "source": [
        "次に、`get_param_rrefs` 関数は、モデルのパラメーターを反復し、（ローカルの）[RRef](https://pytorch.org/docs/stable/rpc.html#torch.distributed.rpc.RRef) としてそれらのパラメーターをラップします。\r\n",
        "\r\n",
        "このメソッドは、RPC経由でトレーナーノードによって呼び出され、最適化の対象となるパラメーターのリストを返します。\r\n",
        "\r\n",
        "このリストは、[分散オプティマイザー](https://pytorch.org/docs/stable/rpc.html#module-torch.distributed.optim) への入力として必要なオブジェクトであり、分散オプティマイザーは最適化する必要のあるすべてのパラメータをRRefのリストとして受け取ります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn6cKnT3EvoV"
      },
      "source": [
        "# 分散自動微分を使用し、モデルのために蓄積された勾配を取得します。\n",
        "# 主に検証目的で使用します。\n",
        "def get_dist_gradients(self, cid):\n",
        "    grads = dist_autograd.get_gradients(cid)\n",
        "    # この出力は、RPC経由でフォワードされますが、1.5.0の時点ではCPUのテンソルしか受け付けていません。\n",
        "    # そのため、テンソルをGPUのメモリに出し入れしなければなりません。\n",
        "    cpu_grads = {}\n",
        "    for k, v in grads.items():\n",
        "        k_cpu, v_cpu = k.to(\"cpu\"), v.to(\"cpu\")\n",
        "        cpu_grads[k_cpu] = v_cpu\n",
        "    return cpu_grads\n",
        "\n",
        "# ローカルパラメーターをRRefにラップします。\n",
        "# これは、リモートでパラメーターの最適化を行うDistributedOptimizerを構築する際に必要になります。\n",
        "def get_param_rrefs(self):\n",
        "    param_rrefs = [rpc.RRef(param) for param in self.model.parameters()]\n",
        "    return param_rrefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPvqHZOrEvoV"
      },
      "source": [
        "最後に、パラメーターサーバーを初期化するメソッドを作成します。\n",
        "\n",
        "なお、プロセス全体にわたってパラメーターサーバーのインスタンスは一つのみであり、すべてのトレーナーが同一のパラメーターサーバーとやり取りをして、格納された同一のモデルパラメーターを更新する点に注意してください。\n",
        "\n",
        "また、`run_parameter_server` を見てわかるように、サーバー自体は独立したアクションを行いません。\n",
        "\n",
        "サーバーはトレーナーからのリクエストを待ち（この部分はまだ定義していません。）、リクエストされた関数を実行することで、トレーナーに応答します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIn7j_MyEvoW"
      },
      "source": [
        "# グローバルパラメーターサーバーインスタンス\n",
        "param_server = None\n",
        "# 一つのパラメーターサーバーであることを担保するためのロック\n",
        "global_lock = Lock()\n",
        "\n",
        "\n",
        "def get_parameter_server(num_gpus=0):\n",
        "    \"\"\"\n",
        "    単一のパラメーターサーバーをすべてのトレーナープロセスに返します。\n",
        "    \"\"\"\n",
        "    global param_server\n",
        "    # ParameterServerへのハンドルを一つのみ得ることを担保します。\n",
        "    with global_lock:\n",
        "        if not param_server:\n",
        "            # 一度だけ構築します。\n",
        "            param_server = ParameterServer(num_gpus=num_gpus)\n",
        "        return param_server\n",
        "\n",
        "def run_parameter_server(rank, world_size):\n",
        "    # パラメーターサーバーは、ただモデルのホストとして振る舞い、\n",
        "    # トレーナーからのリクエストに応答します。\n",
        "    # rpc.shutdown() は、デフォルトではすべてのワーカーが処理を完了するまで待機します。\n",
        "    # 今回のケースでは、パラメーターサーバーはすべてのトレーナーが処理を完了するまで待機し、    \n",
        "    # その後、処理を抜けます。\n",
        "    print(\"PS master initializing RPC\")\n",
        "    rpc.init_rpc(name=\"parameter_server\", rank=rank, world_size=world_size)\n",
        "    print(\"RPC initialized! Running parameter server...\")\n",
        "    rpc.shutdown()\n",
        "    print(\"RPC shutdown on parameter server.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfYBdQHiEvoX"
      },
      "source": [
        "上記の実装コードでは、`rpc.shutdown()` 部分では、即時にパラメーターサーバーがシャットダウンするわけではない点に注意してください。\n",
        "\n",
        "パラメーターサーバーは、すべてのワーカー（今回のケースではトレーナー）が `rpc.shutdown()` を呼び出すまで待機します。\n",
        "\n",
        "これにより、すべての（まだ定義されていない）トレーナーが訓練プロセスを完了する前に、パラメータサーバーがオフラインにならないことを保証しています。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JODyBuzXEvoX"
      },
      "source": [
        "次に、`TrainerNet` クラスを定義します。\n",
        "\n",
        "このクラスは `nn.Module` のサブクラスでもあり、`__init__` メソッドでは `rpc.remote` APIを使用してパラメーターサーバーへのRRef、あるいはリモート参照を取得します。\n",
        "\n",
        "なお、ここではパラメーターサーバーをローカルのプロセスにコピーしていない点に注意してください。\n",
        "\n",
        "そうではなく、 `self.param_server_rref` を、分離したプロセス上に存続するパラメーターサーバーへの分散共有ポインターとして捉えることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1SjgBoJEvoY"
      },
      "source": [
        "# --------- Trainers --------------------\n",
        "\n",
        "# トレーナーによって訓練されるネットワークに対応する nn.Module\n",
        "# forward() メソッドは、単に与えられたパラメーターサーバー上でネットワークを呼び出します。\n",
        "class TrainerNet(nn.Module):\n",
        "    def __init__(self, num_gpus=0):\n",
        "        super().__init__()\n",
        "        self.num_gpus = num_gpus\n",
        "        self.param_server_rref = rpc.remote(\n",
        "            \"parameter_server\", get_parameter_server, args=(num_gpus,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT-u4UC7EvoY"
      },
      "source": [
        "次に `get_global_param_rrefs` というメソッドを定義します。\n",
        "\n",
        "このメソッドの気持ちを理解する上では、[DistributedOptimizer](https://pytorch.org/docs/stable/rpc.html#module-torch.distributed.optim) のドキュメント、中でも特に、APIシグネチャの該当部分を読む必要があります。\n",
        "\n",
        "オプティマイザーは、最適化の対象となるリモートのパラメーターに対応するRRefのリストを渡される必要があるため、ここで必要なRRefを取得します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJFcmCc3Z53F"
      },
      "source": [
        "関数内の処理では、`TrainerNet` がやり取りをする唯一のリモートワーカーが `ParameterServer` であるため、単に `ParameterServer` 上で `remote_method` を呼び出しています。 \r\n",
        "\r\n",
        "そこで、`ParameterServer` クラスで定義した `get_param_rrefs` メソッドを使用しています。このメソッドは、最適化される必要のあるパラメーターへのRRefのリストを返します。\r\n",
        "\r\n",
        "なお、今回のケースでは、`TrainerNet` は独自のパラメーターを定義していない点に留意してください。\r\n",
        "\r\n",
        "もし独自のパラメーターを定義した場合、各パラメーターを一つのRRefにラップし、`DistributedOptimizer` への入力に含める必要が生じます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_87reTgvEvoZ"
      },
      "source": [
        "class TrainerNet(nn.Module):\n",
        "    # ...\n",
        "    def get_global_param_rrefs(self):\n",
        "        remote_params = remote_method(\n",
        "            ParameterServer.get_param_rrefs,\n",
        "            self.param_server_rref)\n",
        "        return remote_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NUteg5IEvoa"
      },
      "source": [
        "これで（同期）RPCを呼び出し、`ParameterServer` 上で定義されたネットワークのフォワードパスを実行する `forward` メソッドを定義する準備ができました。\n",
        "\n",
        "なお、RPCの呼び出しには `ParameterServer` へのリモートのハンドルである `self.param_server_rref` を渡している点に注意してください。\n",
        "\n",
        "この呼び出しにより、`ParameterServer` が実行されているノード上にRPCを送信し、フォワードパスを実行し、モデルの出力に対応するテンソルを返します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajeyg1O_Evoa"
      },
      "source": [
        "class TrainerNet(nn.Module):\n",
        "    # ...\n",
        "    def forward(self, x):\n",
        "        model_output = remote_method(\n",
        "            ParameterServer.forward, self.param_server_rref, x)\n",
        "        return model_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxkfrRXXEvob"
      },
      "source": [
        "トレーナーを完全に定義できたので、次はニューラルネットワークの訓練ループを記述し、ネットワークとオプティマイザーの作成、ネットワークを通した入力の実行、そして損失の計算をできるようにします。\n",
        "\n",
        "訓練ループはローカルの訓練プログラムと似ている点が多くありますが、ネットワークが複数のマシン間に分散されているという性質上、少し手を加えている点があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMEflvuZEvoc"
      },
      "source": [
        "下記の実装コードでは、`TrainerNet` を初期化し、`DistributedOptimizer` を構築しています。\n",
        "\n",
        "なお、先ほど述べたように、`DistributedOptimizer` には最適化を行いたいグローバル（分散訓練に関わっているすべてのノードに渡る）パラメーターのすべてを渡す必要があります。\n",
        "\n",
        "さらに、使用するローカルオプティマイザーを渡します。今回のケースではSGDです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjYnOOMaO7B"
      },
      "source": [
        "ちなみに、ローカルオプティマイザーの作成と同様に、基盤になるオプティマイザーのアルゴリズムを設定することができ、`optimizer.SGD` へのすべての引数は適切に転送されます。\r\n",
        "\r\n",
        "例えば次のコードでは、すべてのローカルオプティマイザーで学習率として使用される独自の学習率を引数で渡しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IoMrrIeEvoc"
      },
      "source": [
        "def run_training_loop(rank, num_gpus, train_loader, test_loader):\n",
        "    # 典型的なニューラルネットワークのフォワード + バックワード + オプティマイザーステップを実行しますが、    \n",
        "    # 分散に適した方法でこれらを実行します。\n",
        "    net = TrainerNet(num_gpus=num_gpus)\n",
        "    # DistributedOptimizerの構築\n",
        "    param_rrefs = net.get_global_param_rrefs()\n",
        "    opt = DistributedOptimizer(optim.SGD, param_rrefs, lr=0.03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McBEWQjLEvod"
      },
      "source": [
        "次に、メインとなる訓練ループを定義します。\n",
        "\n",
        "PyTorchの [DataLoader](https://pytorch.org/docs/stable/data.html) から与えられるイテラブルオブジェクトに対してループします。\n",
        "\n",
        "ですが、典型的なフォワード/バックワード/オプティマイザーのループを記述する前に、分散自動微分のコンテクストにロジックをラップします。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQW2QXJQagJ6"
      },
      "source": [
        "このラップは、モデルのフォワードパス内で呼び出されたRPCを記録するために必要である点に注意してください。\r\n",
        "\r\n",
        "これにより、バックワードパス内に存在するすべての分散ワーカーを含んだ適切なグラフを構築できるようになります。\r\n",
        "\r\n",
        "なお、分散自動微分コンテクストは、特定のイテレーションに対応する勾配を蓄積して最適化するための識別子として機能する `context_id` を返します．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF37jk6EEvod"
      },
      "source": [
        "ローカルワーカー上でバックワードパスを開始する典型的な `loss.backward()` の呼び出しとは違い、context_id と `loss` を引数に`dist_autograd.backward()`を呼び出しますが、この部分がバックワードパスを開始させる起点になっています。\n",
        "\n",
        "そして、この context_id はオプティマイザーの呼び出しにも渡しますが、これは特定のバックワードパスによって計算される勾配をすべてのノードにわたって参照できるようにするために必要なid情報です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3spmLXmCEvoe"
      },
      "source": [
        "def run_training_loop(rank, num_gpus, train_loader, test_loader):\n",
        "    # ...\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "        with dist_autograd.context() as cid:\n",
        "            model_output = net(data)\n",
        "            target = target.to(model_output.device)\n",
        "            loss = F.nll_loss(model_output, target)\n",
        "            if i % 5 == 0:\n",
        "                print(f\"Rank {rank} training batch {i} loss {loss.item()}\")\n",
        "            dist_autograd.backward(cid, [loss])\n",
        "            # 分散自動微分の実行に成功し、勾配が返されたことを確認します。\n",
        "            assert remote_method(\n",
        "                ParameterServer.get_dist_gradients,\n",
        "                net.param_server_rref,\n",
        "                cid) != {}\n",
        "            opt.step(cid)\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    print(\"Getting accuracy....\")\n",
        "    get_accuracy(test_loader, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxK8YMLSEvof"
      },
      "source": [
        "次に示す実装コードは、典型的なローカルモデルと同様に、訓練完了後にモデルの正解率をただ計算しています。\n",
        "\n",
        "しかし先ほど説明したように、この関数に与えた `net` は、`TrainerNet` のインスタンスであるため、フォワードパスは明示的にRPCを呼び出している点に留意してください。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN46wPw4Evof"
      },
      "source": [
        "def get_accuracy(test_loader, model):\n",
        "    model.eval()\n",
        "    correct_sum = 0\n",
        "    # GPUを使用できる場合は、GPUを使用して評価を行います。\n",
        "    device = torch.device(\"cuda:0\" if model.num_gpus > 0\n",
        "        and torch.cuda.is_available() else \"cpu\")\n",
        "    with torch.no_grad():\n",
        "        for i, (data, target) in enumerate(test_loader):\n",
        "            out = model(data, -1)\n",
        "            pred = out.argmax(dim=1, keepdim=True)\n",
        "            pred, target = pred.to(device), target.to(device)\n",
        "            correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "            correct_sum += correct\n",
        "\n",
        "    print(f\"Accuracy {correct_sum / len(test_loader.dataset)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFns2X1ZEvog"
      },
      "source": [
        "次に、RPCの初期化を担当する `ParameterServer` の主要なループとして、 `run_parameter_server` を定義した方法のように、トレーナーに関して同様のループを定義しましょう。\n",
        "\n",
        "`run_parameter_server` との違いは、トレーナーが先ほど定義した訓練ループを実行しなければならない点です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlnXY_m2Evog"
      },
      "source": [
        "# トレーナー用の主要なループ\n",
        "def run_worker(rank, world_size, num_gpus, train_loader, test_loader):\n",
        "    print(f\"Worker rank {rank} initializing RPC\")\n",
        "    rpc.init_rpc(\n",
        "        name=f\"trainer_{rank}\",\n",
        "        rank=rank,\n",
        "        world_size=world_size)\n",
        "\n",
        "    print(f\"Worker {rank} done initializing RPC\")\n",
        "\n",
        "    run_training_loop(rank, num_gpus, train_loader, test_loader)\n",
        "    rpc.shutdown()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rd2PdznEvoh"
      },
      "source": [
        "なお、`run_parameter_server` のときと同様に `rpc.shutdown()` は、ノードを抜ける前にトレーナーとパラメーターサーバーのすべてのワーカーが `rpc.shutdown()` を呼び出すまでは、デフォルトで待機する点に注意してください。\n",
        "\n",
        "\n",
        "これにより、ノードが円滑に終了し、別のノードがオンラインであることを期待している間に、対象のノードがオフラインにならないようにしています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO9_aVBAEvoh"
      },
      "source": [
        "以上でトレーナーとパラメーターサーバーの具体的な実装が完了し、残すはトレーナーとパラメーターサーバーを起動するコードを加えるのみとなりました。\n",
        "\n",
        "初めに、パラメーターサーバーとトレーナーに適用する様々な引数を取る必要があります。\n",
        "\n",
        "`world_size` は、訓練に関わるノード総数に対応しており、つまりすべてのトレーナーとパラメーターサーバーの合計値を表します。\n",
        "\n",
        "また、各プロセスについての一意の `rank` も渡す必要があり、この値は `0` （単一のパラメーターサーバーを実行する場所）から `world_size -1` を取ります。\n",
        "\n",
        "`master_addr` と `master_port` は、ランク0のプロセスがどこで実行されているかを特定する用途があり、各ノードが互いのノードを発見する際に使用されます。\n",
        "\n",
        "この例をローカルで検証するには、単に `localhost` と生成されたすべてのインスタンスへの `master_port` を渡すことになります。\n",
        "\n",
        "なお、説明目的のため、この例は0-2個のGPUの使用のみサポートしていますが、本チュートリアルの実装アプローチは、より多くのGPUを使用している場合であっても適用できる内容になっています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr5rulLYEvoi"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Parameter-Server RPC based training\")\n",
        "    parser.add_argument(\n",
        "        \"--world_size\",\n",
        "        type=int,\n",
        "        default=4,\n",
        "        help=\"\"\"Total number of participating processes. Should be the sum of\n",
        "        master node and all training nodes.\"\"\")\n",
        "    parser.add_argument(\n",
        "        \"rank\",\n",
        "        type=int,\n",
        "        default=None,\n",
        "        help=\"Global rank of this process. Pass in 0 for master.\")\n",
        "    parser.add_argument(\n",
        "        \"num_gpus\",\n",
        "        type=int,\n",
        "        default=0,\n",
        "        help=\"\"\"Number of GPUs to use for training, Currently supports between 0\n",
        "         and 2 GPUs. Note that this argument will be passed to the parameter servers.\"\"\")\n",
        "    parser.add_argument(\n",
        "        \"--master_addr\",\n",
        "        type=str,\n",
        "        default=\"localhost\",\n",
        "        help=\"\"\"Address of master, will default to localhost if not provided.\n",
        "        Master must be able to accept network traffic on the address + port.\"\"\")\n",
        "    parser.add_argument(\n",
        "        \"--master_port\",\n",
        "        type=str,\n",
        "        default=\"29500\",\n",
        "        help=\"\"\"Port that master is listening on, will default to 29500 if not\n",
        "        provided. Master must be able to accept network traffic on the host and port.\"\"\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    assert args.rank is not None, \"must provide rank argument.\"\n",
        "    assert args.num_gpus <= 3, f\"Only 0-2 GPUs currently supported (got {args.num_gpus}).\"\n",
        "    os.environ['MASTER_ADDR'] = args.master_addr\n",
        "    os.environ[\"MASTER_PORT\"] = args.master_port"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8gYDlEGEvoi"
      },
      "source": [
        "コマンドラインの引数によって決まるパラメーターサーバー、またはトレーナーに対応するプロセスを作成するところまで完了しました。\n",
        "\n",
        "ランクが0で渡された場合は `ParameterServer` を作成し、それ以外の場合は `TrainerNet` を作成します。\n",
        "\n",
        "なお、実行したい関数に対応するサブプロセスを起動する際には `torch.multiprocessing` を使用し、メインスレッドから `p.join()` を呼び出して起動したサブプロセスの完了を待機する点に注意してください。\n",
        "\n",
        "そしてトレーナーを初期化する際は、PyTorchの [データローダー](https://pytorch.org/docs/stable/data.html) を用いて、MNISTデータセット内の訓練用のデータローダーとテスト用のデータローダーを指定しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_aFPP9IEvoi"
      },
      "source": [
        "processes = []\n",
        "world_size = args.world_size\n",
        "if args.rank == 0:\n",
        "    p = mp.Process(target=run_parameter_server, args=(0, world_size))\n",
        "    p.start()\n",
        "    processes.append(p)\n",
        "else:\n",
        "    # 訓練に使用するデータを取得\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=32, shuffle=True,)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(\n",
        "            '../data',\n",
        "            train=False,\n",
        "            transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                        ])),\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    # このノード上で訓練ワーカーを開始\n",
        "    p = mp.Process(\n",
        "        target=run_worker,\n",
        "        args=(\n",
        "            args.rank,\n",
        "            world_size, args.num_gpus,\n",
        "            train_loader,\n",
        "            test_loader))\n",
        "    p.start()\n",
        "    processes.append(p)\n",
        "\n",
        "for p in processes:\n",
        "    p.join()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipRqIjMWEvoj"
      },
      "source": [
        "以上の実装例をローカルにて実行する際は、分離したターミナルのウィンドウにおいて、次のコマンドワーカーをサーバーと生成したい各ワーカーに対して実行します。\n",
        "\n",
        "`python rpc_parameter_server.py --world_size=WORLD_SIZE --rank=RANK`\n",
        "\n",
        "そして、例えば、ワールドサイズが2であるマスターノードに対するコマンドは、\n",
        "\n",
        "`python rpc_parameter_server.py --world_size=2 --rank=0` \n",
        "\n",
        "のようになります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkkUL7iTcKly"
      },
      "source": [
        "また、トレーナーであれば、\r\n",
        "\r\n",
        "`python rpc_parameter_server.py --world_size=2 --rank=1`\r\n",
        "\r\n",
        "のコマンドを分離したウィンドウ内で行うことで、起動させることができます。\r\n",
        "\r\n",
        "なお、本チュートリアルは、2個以下のGPUを用いて訓練することを想定していますが、この引数は `--num_gpus=N` を訓練スクリプトに与えることで設定が可能である点に留意してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOM8hsk4Evoj"
      },
      "source": [
        "さらに、コマンドライン引数 `--master_addr=ADDRESS` と `--master_port=PORT` を渡すことで、マスタワーカーがリスニングしているアドレスとポートを指定することもできます。\n",
        "\n",
        "これは例えば、トレーナーとマスターノードが異なりマシン上で実行されている場合において、機能をテストする際に役立ちます。"
      ]
    }
  ]
}